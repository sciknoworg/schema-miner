{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.46950354609929074,
            "rouge2": 0.23153409090909094,
            "rougeL": 0.2723404255319149,
            "rougeLsum": 0.2723404255319149,
            "bleu": {
                "bleu": 0.208123500664727,
                "precisions": [
                    0.37037037037037035,
                    0.24686431014823262,
                    0.1728465487735311,
                    0.1187214611872146
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 2.0454545454545454,
                "translation_length": 1755,
                "reference_length": 858
            },
            "bert": {
                "precision": 0.7669748465220133,
                "recall": 0.7552582820256551,
                "f1": 0.7610370914141337
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5415676959619953,
            "rouge2": 0.2309523809523809,
            "rougeL": 0.32066508313539194,
            "rougeLsum": 0.32066508313539194,
            "bleu": {
                "bleu": 0.28592768499065857,
                "precisions": [
                    0.6548797736916548,
                    0.43342776203966005,
                    0.2822695035460993,
                    0.19602272727272727
                ],
                "brevity_penalty": 0.8076887535235029,
                "length_ratio": 0.824009324009324,
                "translation_length": 707,
                "reference_length": 858
            },
            "bert": {
                "precision": 0.8120052019755045,
                "recall": 0.7203803261121114,
                "f1": 0.7631112535794576
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.46950354609929074,
            "rouge2": 0.23153409090909094,
            "rougeL": 0.2723404255319149,
            "rougeLsum": 0.2723404255319149,
            "bleu": {
                "bleu": 0.14978373869640713,
                "precisions": [
                    0.7575757575757576,
                    0.5052508751458576,
                    0.35397196261682246,
                    0.2432748538011696
                ],
                "brevity_penalty": 0.3515319957864631,
                "length_ratio": 0.4888888888888889,
                "translation_length": 858,
                "reference_length": 1755
            },
            "bert": {
                "precision": 0.7552582621574402,
                "recall": 0.7669748465220133,
                "f1": 0.7610370914141337
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.38785046728971956,
            "rouge2": 0.1809672386895476,
            "rougeL": 0.25233644859813087,
            "rougeLsum": 0.25233644859813087,
            "bleu": {
                "bleu": 0.08909196360491098,
                "precisions": [
                    0.7609618104667609,
                    0.5084985835694051,
                    0.3191489361702128,
                    0.19176136363636365
                ],
                "brevity_penalty": 0.22711025818723252,
                "length_ratio": 0.4028490028490028,
                "translation_length": 707,
                "reference_length": 1755
            },
            "bert": {
                "precision": 0.7880254785219828,
                "recall": 0.7162403265635172,
                "f1": 0.7499521374702454
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.5415676959619953,
            "rouge2": 0.2309523809523809,
            "rougeL": 0.32066508313539194,
            "rougeLsum": 0.32066508313539194,
            "bleu": {
                "bleu": 0.29159605745954,
                "precisions": [
                    0.5396270396270396,
                    0.3570595099183197,
                    0.2324766355140187,
                    0.16140350877192983
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.2135785007072135,
                "translation_length": 858,
                "reference_length": 707
            },
            "bert": {
                "precision": 0.7203803261121114,
                "recall": 0.8120052218437195,
                "f1": 0.7631112337112427
            }
        },
        "gpt-4o": {
            "rouge1": 0.38785046728971956,
            "rouge2": 0.1809672386895476,
            "rougeL": 0.25233644859813087,
            "rougeLsum": 0.25233644859813087,
            "bleu": {
                "bleu": 0.15783109543587803,
                "precisions": [
                    0.30655270655270656,
                    0.20467502850627137,
                    0.12835139760410724,
                    0.07705479452054795
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 2.4823196605374824,
                "translation_length": 1755,
                "reference_length": 707
            },
            "bert": {
                "precision": 0.7162403265635172,
                "recall": 0.7880254983901978,
                "f1": 0.7499521374702454
            }
        }
    }
}