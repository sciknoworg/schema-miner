{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.16346583296114336,
            "rouge2": 0.08404112650871703,
            "rougeL": 0.10897722197409557,
            "rougeLsum": 0.10897722197409557,
            "bleu": {
                "bleu": 0.05539019115776784,
                "precisions": [
                    0.09102663563485906,
                    0.06285566476978789,
                    0.04708926261319534,
                    0.03493788819875776
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 8.993023255813954,
                "translation_length": 3867,
                "reference_length": 430
            },
            "bert": {
                "precision": 0.7372414171695709,
                "recall": 0.7563664019107819,
                "f1": 0.7462340593338013
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.3361344537815126,
            "rouge2": 0.12359550561797755,
            "rougeL": 0.24649859943977592,
            "rougeLsum": 0.24649859943977592,
            "bleu": {
                "bleu": 0.1375900665035654,
                "precisions": [
                    0.2676822633297062,
                    0.1721132897603486,
                    0.1079607415485278,
                    0.07205240174672489
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 2.1372093023255814,
                "translation_length": 919,
                "reference_length": 430
            },
            "bert": {
                "precision": 0.7441054880619049,
                "recall": 0.7079191207885742,
                "f1": 0.7253696322441101
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.16346583296114336,
            "rouge2": 0.08404112650871703,
            "rougeL": 0.10897722197409557,
            "rougeLsum": 0.10897722197409557,
            "bleu": {
                "bleu": 0.00016879643953837732,
                "precisions": [
                    0.8186046511627907,
                    0.5664335664335665,
                    0.4252336448598131,
                    0.3161592505854801
                ],
                "brevity_penalty": 0.00033781124817621095,
                "length_ratio": 0.11119731057667442,
                "translation_length": 430,
                "reference_length": 3867
            },
            "bert": {
                "precision": 0.7563663721084595,
                "recall": 0.7372414171695709,
                "f1": 0.7462340593338013
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.3014141414141414,
            "rouge2": 0.15770319450060655,
            "rougeL": 0.1898989898989899,
            "rougeLsum": 0.1898989898989899,
            "bleu": {
                "bleu": 0.01624041903380605,
                "precisions": [
                    0.7584330794341676,
                    0.5021786492374728,
                    0.3326063249727372,
                    0.2052401746724891
                ],
                "brevity_penalty": 0.04044409605153314,
                "length_ratio": 0.23765192655805534,
                "translation_length": 919,
                "reference_length": 3867
            },
            "bert": {
                "precision": 0.7672682851552963,
                "recall": 0.7134948819875717,
                "f1": 0.7391177117824554
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.3361344537815126,
            "rouge2": 0.12359550561797755,
            "rougeL": 0.24649859943977592,
            "rougeLsum": 0.24649859943977592,
            "bleu": {
                "bleu": 0.094484323592633,
                "precisions": [
                    0.5720930232558139,
                    0.3682983682983683,
                    0.23130841121495327,
                    0.15456674473067916
                ],
                "brevity_penalty": 0.320712786550251,
                "length_ratio": 0.46789989118607184,
                "translation_length": 430,
                "reference_length": 919
            },
            "bert": {
                "precision": 0.7079191207885742,
                "recall": 0.7441054582595825,
                "f1": 0.7253696024417877
            }
        },
        "gpt-4o": {
            "rouge1": 0.3014141414141414,
            "rouge2": 0.15770319450060655,
            "rougeL": 0.1898989898989899,
            "rougeLsum": 0.1898989898989899,
            "bleu": {
                "bleu": 0.09531081618103997,
                "precisions": [
                    0.18024308249288853,
                    0.11924469736161407,
                    0.07891332470892626,
                    0.048654244306418216
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 4.207834602829162,
                "translation_length": 3867,
                "reference_length": 919
            },
            "bert": {
                "precision": 0.7134948670864105,
                "recall": 0.7672682851552963,
                "f1": 0.7391177117824554
            }
        }
    }
}