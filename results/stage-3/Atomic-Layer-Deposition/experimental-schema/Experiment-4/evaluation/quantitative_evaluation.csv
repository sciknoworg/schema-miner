Reference,Comparison,rouge1,rouge2,rougeL,rougeLsum,bleu_bleu,bleu_precisions,bleu_brevity_penalty,bleu_length_ratio,bleu_translation_length,bleu_reference_length,bert_precision,bert_recall,bert_f1
gpt-4-turbo,gpt-4o,0.256873823,0.105540897,0.141619586,0.141619586,0.116938785,"[0.2236976506639428, 0.15197956577266922, 0.09197751660705161, 0.059800664451827246]",1,3.769008662,3916,1039,0.693043858,0.713395029,0.70274502
,meta-llama-3.1-8b-instruct,0.32744043,0.101616628,0.184473482,0.184473482,0.171167227,"[0.44082125603864736, 0.2525679758308157, 0.11910519951632406, 0.0647307924984876]",1,1.593840231,1656,1039,0.700961828,0.708694652,0.704648197
gpt-4o,gpt-4-turbo,0.256873823,0.105540897,0.141619586,0.141619586,0.02767463,"[0.8431183830606352, 0.5732177263969171, 0.3471552555448409, 0.22586872586872586]",0.062724155,0.265321757,1039,3916,0.713395029,0.693043858,0.70274502
,meta-llama-3.1-8b-instruct,0.378145695,0.15175613,0.197350993,0.197350993,0.101692684,"[0.7572463768115942, 0.5045317220543807, 0.3282950423216445, 0.20024198427102238]",0.25544854,0.42288049,1656,3916,0.770294696,0.737022877,0.753126373
meta-llama-3.1-8b-instruct,gpt-4-turbo,0.32744043,0.101616628,0.184473482,0.184473482,0.150729375,"[0.7025986525505293, 0.4026974951830443, 0.18997107039537126, 0.10328185328185328]",0.552202622,0.627415459,1039,1656,0.708694652,0.700961828,0.704648197
,gpt-4o,0.378145695,0.15175613,0.197350993,0.197350993,0.168258371,"[0.3202247191011236, 0.21328224776500637, 0.1387327542156362, 0.08458982877587529]",1,2.3647343,3916,1656,0.737022887,0.770294686,0.753126363
