{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.5035074045206547,
            "rouge2": 0.2576112412177986,
            "rougeL": 0.33203429462197975,
            "rougeLsum": 0.33203429462197975,
            "bleu": {
                "bleu": 0.2738256338277264,
                "precisions": [
                    0.428842504743833,
                    0.30443037974683546,
                    0.23432552248258393,
                    0.18377693282636248
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.851288056206089,
                "translation_length": 1581,
                "reference_length": 854
            },
            "bert": {
                "precision": 0.7904404004414877,
                "recall": 0.7771955728530884,
                "f1": 0.7837405800819397
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5216494845360825,
            "rouge2": 0.22107438016528924,
            "rougeL": 0.3154639175257732,
            "rougeLsum": 0.3154639175257732,
            "bleu": {
                "bleu": 0.27248290517038887,
                "precisions": [
                    0.591743119266055,
                    0.3467278989667049,
                    0.2103448275862069,
                    0.1277330264672037
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.0210772833723654,
                "translation_length": 872,
                "reference_length": 854
            },
            "bert": {
                "precision": 0.7766372760136923,
                "recall": 0.7427937189737955,
                "f1": 0.7590131163597107
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.5035074045206547,
            "rouge2": 0.2576112412177986,
            "rougeL": 0.33203429462197975,
            "rougeLsum": 0.33203429462197975,
            "bleu": {
                "bleu": 0.21656581470659161,
                "precisions": [
                    0.7939110070257611,
                    0.5638921453692849,
                    0.43427230046948356,
                    0.3407755581668625
                ],
                "brevity_penalty": 0.42686475190053424,
                "length_ratio": 0.5401644528779254,
                "translation_length": 854,
                "reference_length": 1581
            },
            "bert": {
                "precision": 0.7771956125895182,
                "recall": 0.7904404004414877,
                "f1": 0.7837405999501547
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5202135774218155,
            "rouge2": 0.23834988540870894,
            "rougeL": 0.31578947368421056,
            "rougeLsum": 0.31578947368421056,
            "bleu": {
                "bleu": 0.14684562316197955,
                "precisions": [
                    0.7075688073394495,
                    0.4431687715269805,
                    0.26436781609195403,
                    0.14499424626006904
                ],
                "brevity_penalty": 0.4434929407500815,
                "length_ratio": 0.551549652118912,
                "translation_length": 872,
                "reference_length": 1581
            },
            "bert": {
                "precision": 0.8190994262695312,
                "recall": 0.7874551216761271,
                "f1": 0.8028509815533956
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.5216494845360825,
            "rouge2": 0.22107438016528924,
            "rougeL": 0.3154639175257732,
            "rougeLsum": 0.3154639175257732,
            "bleu": {
                "bleu": 0.2724331276020037,
                "precisions": [
                    0.6042154566744731,
                    0.3540445486518171,
                    0.2147887323943662,
                    0.13043478260869565
                ],
                "brevity_penalty": 0.9791432901498184,
                "length_ratio": 0.9793577981651376,
                "translation_length": 854,
                "reference_length": 872
            },
            "bert": {
                "precision": 0.7427937189737955,
                "recall": 0.7766372760136923,
                "f1": 0.7590131163597107
            }
        },
        "gpt-4o": {
            "rouge1": 0.5202135774218155,
            "rouge2": 0.23834988540870894,
            "rougeL": 0.31578947368421056,
            "rougeLsum": 0.31578947368421056,
            "bleu": {
                "bleu": 0.1824833272966113,
                "precisions": [
                    0.3902593295382669,
                    0.24430379746835443,
                    0.14566181127295758,
                    0.07984790874524715
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.813073394495413,
                "translation_length": 1581,
                "reference_length": 872
            },
            "bert": {
                "precision": 0.7874551216761271,
                "recall": 0.8190994262695312,
                "f1": 0.8028509815533956
            }
        }
    }
}