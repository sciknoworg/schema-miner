Reference,Comparison,rouge1,rouge2,rougeL,rougeLsum,bleu_bleu,bleu_precisions,bleu_brevity_penalty,bleu_length_ratio,bleu_translation_length,bleu_reference_length,bert_precision,bert_recall,bert_f1
gpt-4-turbo,gpt-4o,0.323678161,0.172112287,0.204137931,0.204137931,0.115761663,"[0.20006090133982948, 0.1370697532744441, 0.09811090798293723, 0.06674794270039622]",1,3.970979444,3284,827,0.744817436,0.762730141,0.75324585
,meta-llama-3.1-8b-instruct,0.410309278,0.121900826,0.235051546,0.235051546,0.204269919,"[0.45067497403946, 0.262993762993763, 0.16024973985431842, 0.09166666666666666]",1,1.164449819,963,827,0.735193113,0.731410642,0.732812126
gpt-4o,gpt-4-turbo,0.323678161,0.172112287,0.204137931,0.204137931,0.023592437,"[0.7944377267230955, 0.5447941888619855, 0.3903030303030303, 0.2657766990291262]",0.051253086,0.25182704,827,3284,0.762730122,0.744817436,0.75324585
,meta-llama-3.1-8b-instruct,0.299863698,0.14097317,0.176283507,0.176283507,0.037321022,"[0.7590861889927311, 0.49064449064449067, 0.34027055150884494, 0.23541666666666666]",0.089799441,0.293239951,963,3284,0.732628405,0.692810565,0.71200186
meta-llama-3.1-8b-instruct,gpt-4-turbo,0.410309278,0.121900826,0.235051546,0.235051546,0.201844576,"[0.524788391777509, 0.3062953995157385, 0.18666666666666668, 0.10679611650485436]",0.848360328,0.858774663,827,963,0.731410662,0.735193113,0.732812126
,gpt-4o,0.299863698,0.14097317,0.176283507,0.176283507,0.121737445,"[0.2225943970767357, 0.14377094121230583, 0.09963436928702012, 0.06888143858579701]",1,3.410176532,3284,963,0.692810565,0.73262842,0.712001875
