{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.32367816091954016,
            "rouge2": 0.17211228716060747,
            "rougeL": 0.20413793103448277,
            "rougeLsum": 0.20413793103448277,
            "bleu": {
                "bleu": 0.1157616632099682,
                "precisions": [
                    0.20006090133982948,
                    0.1370697532744441,
                    0.09811090798293723,
                    0.06674794270039622
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 3.970979443772672,
                "translation_length": 3284,
                "reference_length": 827
            },
            "bert": {
                "precision": 0.7448174357414246,
                "recall": 0.7627301414807638,
                "f1": 0.7532458504041036
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.41030927835051545,
            "rouge2": 0.121900826446281,
            "rougeL": 0.23505154639175255,
            "rougeLsum": 0.23505154639175255,
            "bleu": {
                "bleu": 0.20426991865461397,
                "precisions": [
                    0.45067497403946,
                    0.262993762993763,
                    0.16024973985431842,
                    0.09166666666666666
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.1644498186215235,
                "translation_length": 963,
                "reference_length": 827
            },
            "bert": {
                "precision": 0.735193113485972,
                "recall": 0.7314106424649557,
                "f1": 0.7328121264775594
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.32367816091954016,
            "rouge2": 0.17211228716060747,
            "rougeL": 0.20413793103448277,
            "rougeLsum": 0.20413793103448277,
            "bleu": {
                "bleu": 0.02359243732074142,
                "precisions": [
                    0.7944377267230955,
                    0.5447941888619855,
                    0.3903030303030303,
                    0.2657766990291262
                ],
                "brevity_penalty": 0.05125308622395696,
                "length_ratio": 0.2518270401948843,
                "translation_length": 827,
                "reference_length": 3284
            },
            "bert": {
                "precision": 0.7627301216125488,
                "recall": 0.7448174357414246,
                "f1": 0.7532458504041036
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.29986369831894594,
            "rouge2": 0.1409731696225557,
            "rougeL": 0.17628350749659244,
            "rougeLsum": 0.17628350749659244,
            "bleu": {
                "bleu": 0.03732102206822394,
                "precisions": [
                    0.7590861889927311,
                    0.49064449064449067,
                    0.34027055150884494,
                    0.23541666666666666
                ],
                "brevity_penalty": 0.08979944072753238,
                "length_ratio": 0.29323995127892816,
                "translation_length": 963,
                "reference_length": 3284
            },
            "bert": {
                "precision": 0.7326284050941467,
                "recall": 0.6928105652332306,
                "f1": 0.7120018601417542
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.41030927835051545,
            "rouge2": 0.121900826446281,
            "rougeL": 0.23505154639175255,
            "rougeLsum": 0.23505154639175255,
            "bleu": {
                "bleu": 0.20184457571633355,
                "precisions": [
                    0.524788391777509,
                    0.3062953995157385,
                    0.18666666666666668,
                    0.10679611650485436
                ],
                "brevity_penalty": 0.8483603277668913,
                "length_ratio": 0.8587746625129803,
                "translation_length": 827,
                "reference_length": 963
            },
            "bert": {
                "precision": 0.7314106623331705,
                "recall": 0.735193113485972,
                "f1": 0.7328121264775594
            }
        },
        "gpt-4o": {
            "rouge1": 0.29986369831894594,
            "rouge2": 0.1409731696225557,
            "rougeL": 0.17628350749659244,
            "rougeLsum": 0.17628350749659244,
            "bleu": {
                "bleu": 0.1217374449015926,
                "precisions": [
                    0.2225943970767357,
                    0.14377094121230583,
                    0.09963436928702012,
                    0.06888143858579701
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 3.410176531671859,
                "translation_length": 3284,
                "reference_length": 963
            },
            "bert": {
                "precision": 0.6928105652332306,
                "recall": 0.7326284199953079,
                "f1": 0.7120018750429153
            }
        }
    }
}