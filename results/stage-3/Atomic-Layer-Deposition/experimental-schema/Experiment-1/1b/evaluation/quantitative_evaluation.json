{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.6519337016574586,
            "rouge2": 0.3344407530454042,
            "rougeL": 0.36906077348066296,
            "rougeLsum": 0.36906077348066296,
            "bleu": {
                "bleu": 0.41510322196095306,
                "precisions": [
                    0.7217090069284064,
                    0.484393063583815,
                    0.3506944444444444,
                    0.2421784472769409
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.0023148148148149,
                "translation_length": 866,
                "reference_length": 864
            },
            "bert": {
                "precision": 0.8091025352478027,
                "recall": 0.800513744354248,
                "f1": 0.8046629627545675
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5421686746987951,
            "rouge2": 0.23671497584541065,
            "rougeL": 0.2891566265060241,
            "rougeLsum": 0.2891566265060241,
            "bleu": {
                "bleu": 0.23925192896101563,
                "precisions": [
                    0.6313497822931785,
                    0.3866279069767442,
                    0.25181950509461426,
                    0.14723032069970846
                ],
                "brevity_penalty": 0.7756985570117549,
                "length_ratio": 0.7974537037037037,
                "translation_length": 689,
                "reference_length": 864
            },
            "bert": {
                "precision": 0.771515945593516,
                "recall": 0.7413816650708517,
                "f1": 0.7560643951098124
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.6519337016574586,
            "rouge2": 0.3344407530454042,
            "rougeL": 0.36906077348066296,
            "rougeLsum": 0.36906077348066296,
            "bleu": {
                "bleu": 0.4151037803938435,
                "precisions": [
                    0.7233796296296297,
                    0.4855156431054461,
                    0.351508120649652,
                    0.24274099883855982
                ],
                "brevity_penalty": 0.9976878623029228,
                "length_ratio": 0.9976905311778291,
                "translation_length": 864,
                "reference_length": 866
            },
            "bert": {
                "precision": 0.800513744354248,
                "recall": 0.8091025352478027,
                "f1": 0.8046629627545675
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5397653194263364,
            "rouge2": 0.23529411764705882,
            "rougeL": 0.333767926988266,
            "rougeLsum": 0.333767926988266,
            "bleu": {
                "bleu": 0.33979021903793,
                "precisions": [
                    0.7097242380261248,
                    0.5130813953488372,
                    0.3813682678311499,
                    0.26822157434402333
                ],
                "brevity_penalty": 0.7734501569736918,
                "length_ratio": 0.7956120092378753,
                "translation_length": 689,
                "reference_length": 866
            },
            "bert": {
                "precision": 0.7810967763264974,
                "recall": 0.763265589872996,
                "f1": 0.7716812292734782
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.5421686746987951,
            "rouge2": 0.23671497584541065,
            "rougeL": 0.2891566265060241,
            "rougeLsum": 0.2891566265060241,
            "bleu": {
                "bleu": 0.24585319341108963,
                "precisions": [
                    0.5034722222222222,
                    0.3082271147161066,
                    0.20069605568445475,
                    0.1173054587688734
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.2539912917271407,
                "translation_length": 864,
                "reference_length": 689
            },
            "bert": {
                "precision": 0.7413816650708517,
                "recall": 0.771515965461731,
                "f1": 0.7560644149780273
            }
        },
        "gpt-4o": {
            "rouge1": 0.5397653194263364,
            "rouge2": 0.23529411764705882,
            "rougeL": 0.333767926988266,
            "rougeLsum": 0.333767926988266,
            "bleu": {
                "bleu": 0.34937034222360136,
                "precisions": [
                    0.5646651270207852,
                    0.40809248554913297,
                    0.30324074074074076,
                    0.21320973348783315
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.2568940493468794,
                "translation_length": 866,
                "reference_length": 689
            },
            "bert": {
                "precision": 0.7632656097412109,
                "recall": 0.7810967763264974,
                "f1": 0.7716812094052633
            }
        }
    }
}