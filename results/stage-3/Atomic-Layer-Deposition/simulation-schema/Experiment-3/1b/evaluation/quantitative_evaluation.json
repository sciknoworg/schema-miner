{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.5210843373493976,
            "rouge2": 0.25075528700906347,
            "rougeL": 0.3192771084337349,
            "rougeLsum": 0.3192771084337349,
            "bleu": {
                "bleu": 0.25074258690317597,
                "precisions": [
                    0.44331210191082804,
                    0.30357142857142855,
                    0.210727969348659,
                    0.13938618925831203
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.7483296213808464,
                "translation_length": 785,
                "reference_length": 449
            },
            "bert": {
                "precision": 0.7628141641616821,
                "recall": 0.7786320745944977,
                "f1": 0.769783616065979
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.35466666666666663,
            "rouge2": 0.12566844919786097,
            "rougeL": 0.2346666666666667,
            "rougeLsum": 0.2346666666666667,
            "bleu": {
                "bleu": 0.16526993808888069,
                "precisions": [
                    0.2811565304087737,
                    0.19760479041916168,
                    0.14285714285714285,
                    0.094
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 2.2338530066815143,
                "translation_length": 1003,
                "reference_length": 449
            },
            "bert": {
                "precision": 0.7482399940490723,
                "recall": 0.7535148859024048,
                "f1": 0.7503165006637573
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.5210843373493976,
            "rouge2": 0.25075528700906347,
            "rougeL": 0.3192771084337349,
            "rougeLsum": 0.3192771084337349,
            "bleu": {
                "bleu": 0.20772059186187877,
                "precisions": [
                    0.7750556792873051,
                    0.53125,
                    0.3691275167785235,
                    0.24439461883408073
                ],
                "brevity_penalty": 0.47315624308843884,
                "length_ratio": 0.5719745222929936,
                "translation_length": 449,
                "reference_length": 785
            },
            "bert": {
                "precision": 0.7786320745944977,
                "recall": 0.7628141939640045,
                "f1": 0.769783616065979
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.4797297297297297,
            "rouge2": 0.15349887133182843,
            "rougeL": 0.29054054054054057,
            "rougeLsum": 0.29054054054054057,
            "bleu": {
                "bleu": 0.23302537051523023,
                "precisions": [
                    0.48753738783649053,
                    0.3023952095808383,
                    0.18181818181818182,
                    0.11
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.2777070063694267,
                "translation_length": 1003,
                "reference_length": 785
            },
            "bert": {
                "precision": 0.7660196820894877,
                "recall": 0.7695815761884054,
                "f1": 0.7675884564717611
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.35466666666666663,
            "rouge2": 0.12566844919786097,
            "rougeL": 0.2346666666666667,
            "rougeLsum": 0.2346666666666667,
            "bleu": {
                "bleu": 0.10769543899955528,
                "precisions": [
                    0.6280623608017817,
                    0.4419642857142857,
                    0.319910514541387,
                    0.21076233183856502
                ],
                "brevity_penalty": 0.29116853928042213,
                "length_ratio": 0.4476570289132602,
                "translation_length": 449,
                "reference_length": 1003
            },
            "bert": {
                "precision": 0.7535148561000824,
                "recall": 0.7482399940490723,
                "f1": 0.7503165006637573
            }
        },
        "gpt-4o": {
            "rouge1": 0.4797297297297297,
            "rouge2": 0.15349887133182843,
            "rougeL": 0.29054054054054057,
            "rougeLsum": 0.29054054054054057,
            "bleu": {
                "bleu": 0.22563616574042125,
                "precisions": [
                    0.6229299363057325,
                    0.3864795918367347,
                    0.23243933588761176,
                    0.14066496163682865
                ],
                "brevity_penalty": 0.7575187371678416,
                "length_ratio": 0.7826520438683948,
                "translation_length": 785,
                "reference_length": 1003
            },
            "bert": {
                "precision": 0.7695815960566202,
                "recall": 0.7660196820894877,
                "f1": 0.7675884564717611
            }
        }
    }
}