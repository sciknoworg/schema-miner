{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.3007071082992185,
            "rouge2": 0.12737430167597766,
            "rougeL": 0.15407517677707483,
            "rougeLsum": 0.15407517677707483,
            "bleu": {
                "bleu": 0.1037614688669064,
                "precisions": [
                    0.18967709127892193,
                    0.12360122075279756,
                    0.08674637496820148,
                    0.056997455470737916
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 4.101147028154328,
                "translation_length": 3933,
                "reference_length": 959
            },
            "bert": {
                "precision": 0.7677811582883199,
                "recall": 0.7279697060585022,
                "f1": 0.7473337650299072
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.3118580765639589,
            "rouge2": 0.06735266604303088,
            "rougeL": 0.1811391223155929,
            "rougeLsum": 0.1811391223155929,
            "bleu": {
                "bleu": 0.19322676738029107,
                "precisions": [
                    0.453740157480315,
                    0.26403940886699506,
                    0.14201183431952663,
                    0.08193484698914116
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.059436913451512,
                "translation_length": 1016,
                "reference_length": 959
            },
            "bert": {
                "precision": 0.7366141478220621,
                "recall": 0.6734782258669535,
                "f1": 0.7033650477727255
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.3007071082992185,
            "rouge2": 0.12737430167597766,
            "rougeL": 0.15407517677707483,
            "rougeLsum": 0.15407517677707483,
            "bleu": {
                "bleu": 0.019171003436611732,
                "precisions": [
                    0.7778936392075079,
                    0.5073068893528184,
                    0.3563218390804598,
                    0.23430962343096234
                ],
                "brevity_penalty": 0.04499755931377778,
                "length_ratio": 0.24383422323925757,
                "translation_length": 959,
                "reference_length": 3933
            },
            "bert": {
                "precision": 0.7279697060585022,
                "recall": 0.7677811781565348,
                "f1": 0.7473337848981222
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.27666151468315303,
            "rouge2": 0.09744779582366589,
            "rougeL": 0.15610510046367856,
            "rougeLsum": 0.15610510046367856,
            "bleu": {
                "bleu": 0.01982019327298479,
                "precisions": [
                    0.7952755905511811,
                    0.4768472906403941,
                    0.26528599605522685,
                    0.14906219151036526
                ],
                "brevity_penalty": 0.056638688089533464,
                "length_ratio": 0.258326976862446,
                "translation_length": 1016,
                "reference_length": 3933
            },
            "bert": {
                "precision": 0.7628907710313797,
                "recall": 0.7396215498447418,
                "f1": 0.750905379652977
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.3118580765639589,
            "rouge2": 0.06735266604303088,
            "rougeL": 0.1811391223155929,
            "rougeLsum": 0.1811391223155929,
            "bleu": {
                "bleu": 0.1929156523479651,
                "precisions": [
                    0.4807090719499479,
                    0.2797494780793319,
                    0.15047021943573669,
                    0.08682008368200837
                ],
                "brevity_penalty": 0.942294977853954,
                "length_ratio": 0.9438976377952756,
                "translation_length": 959,
                "reference_length": 1016
            },
            "bert": {
                "precision": 0.6734782059987386,
                "recall": 0.7366141478220621,
                "f1": 0.7033650477727255
            }
        },
        "gpt-4o": {
            "rouge1": 0.27666151468315303,
            "rouge2": 0.09744779582366589,
            "rougeL": 0.15610510046367856,
            "rougeLsum": 0.15610510046367856,
            "bleu": {
                "bleu": 0.09030009869585999,
                "precisions": [
                    0.205441139079583,
                    0.12309257375381485,
                    0.06843042482828797,
                    0.038422391857506365
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 3.8710629921259843,
                "translation_length": 3933,
                "reference_length": 1016
            },
            "bert": {
                "precision": 0.7396215200424194,
                "recall": 0.7628907859325409,
                "f1": 0.7509053498506546
            }
        }
    }
}