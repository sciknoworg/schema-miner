{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.2664601084430674,
            "rouge2": 0.1449612403100775,
            "rougeL": 0.14484895429899305,
            "rougeLsum": 0.14484895429899305,
            "bleu": {
                "bleu": 0.09465706270023626,
                "precisions": [
                    0.15942028985507245,
                    0.11197200699825044,
                    0.08175,
                    0.05501375343835959
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 5.177231565329883,
                "translation_length": 4002,
                "reference_length": 773
            },
            "bert": {
                "precision": 0.718221644560496,
                "recall": 0.7161421577135721,
                "f1": 0.7166862487792969
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.2968197879858657,
            "rouge2": 0.07319952774498228,
            "rougeL": 0.17196702002355715,
            "rougeLsum": 0.17196702002355715,
            "bleu": {
                "bleu": 0.19547418388137294,
                "precisions": [
                    0.4143763213530655,
                    0.26455026455026454,
                    0.16101694915254236,
                    0.08271474019088017
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.2238033635187582,
                "translation_length": 946,
                "reference_length": 773
            },
            "bert": {
                "precision": 0.6950119932492574,
                "recall": 0.6586386958758036,
                "f1": 0.6759682099024454
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.2664601084430674,
            "rouge2": 0.1449612403100775,
            "rougeL": 0.14484895429899305,
            "rougeLsum": 0.14484895429899305,
            "bleu": {
                "bleu": 0.007529795626051032,
                "precisions": [
                    0.8253557567917206,
                    0.5803108808290155,
                    0.42412451361867703,
                    0.2857142857142857
                ],
                "brevity_penalty": 0.015340919165256489,
                "length_ratio": 0.19315342328835583,
                "translation_length": 773,
                "reference_length": 4002
            },
            "bert": {
                "precision": 0.7161421775817871,
                "recall": 0.718221644560496,
                "f1": 0.7166862686475118
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.21709741550695827,
            "rouge2": 0.06446478312773578,
            "rougeL": 0.11928429423459244,
            "rougeLsum": 0.11928429423459244,
            "bleu": {
                "bleu": 0.015412453828585616,
                "precisions": [
                    0.781183932346723,
                    0.4846560846560847,
                    0.3125,
                    0.1951219512195122
                ],
                "brevity_penalty": 0.03953994016059064,
                "length_ratio": 0.23638180909545228,
                "translation_length": 946,
                "reference_length": 4002
            },
            "bert": {
                "precision": 0.7193606644868851,
                "recall": 0.6692554652690887,
                "f1": 0.6921954154968262
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.2968197879858657,
            "rouge2": 0.07319952774498228,
            "rougeL": 0.17196702002355715,
            "rougeLsum": 0.17196702002355715,
            "bleu": {
                "bleu": 0.19131940713708928,
                "precisions": [
                    0.5071151358344114,
                    0.3238341968911917,
                    0.19714656290531776,
                    0.1012987012987013
                ],
                "brevity_penalty": 0.7994723243389258,
                "length_ratio": 0.8171247357293869,
                "translation_length": 773,
                "reference_length": 946
            },
            "bert": {
                "precision": 0.6586386958758036,
                "recall": 0.6950119932492574,
                "f1": 0.6759682099024454
            }
        },
        "gpt-4o": {
            "rouge1": 0.21709741550695827,
            "rouge2": 0.06446478312773578,
            "rougeL": 0.11928429423459244,
            "rougeLsum": 0.11928429423459244,
            "bleu": {
                "bleu": 0.0920286775058909,
                "precisions": [
                    0.18465767116441778,
                    0.11447138215446138,
                    0.07375,
                    0.04601150287571893
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 4.230443974630021,
                "translation_length": 4002,
                "reference_length": 946
            },
            "bert": {
                "precision": 0.6692554578185081,
                "recall": 0.7193606644868851,
                "f1": 0.692195400595665
            }
        }
    }
}