{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.5220417633410672,
            "rouge2": 0.24418604651162795,
            "rougeL": 0.3178654292343388,
            "rougeLsum": 0.3178654292343388,
            "bleu": {
                "bleu": 0.25259864271060106,
                "precisions": [
                    0.4481086323957323,
                    0.30970873786407765,
                    0.2108843537414966,
                    0.13910505836575876
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.7806563039723662,
                "translation_length": 1031,
                "reference_length": 579
            },
            "bert": {
                "precision": 0.7795332372188568,
                "recall": 0.7939199209213257,
                "f1": 0.7866585552692413
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.4241610738255034,
            "rouge2": 0.12113055181695828,
            "rougeL": 0.2711409395973155,
            "rougeLsum": 0.2711409395973155,
            "bleu": {
                "bleu": 0.22868743793116555,
                "precisions": [
                    0.40324449594438005,
                    0.27610208816705334,
                    0.19744483159117304,
                    0.12441860465116279
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.4905008635578583,
                "translation_length": 863,
                "reference_length": 579
            },
            "bert": {
                "precision": 0.7392719686031342,
                "recall": 0.733940601348877,
                "f1": 0.7364138960838318
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.5220417633410672,
            "rouge2": 0.24418604651162795,
            "rougeL": 0.3178654292343388,
            "rougeLsum": 0.3178654292343388,
            "bleu": {
                "bleu": 0.20628669015698378,
                "precisions": [
                    0.7979274611398963,
                    0.5519031141868512,
                    0.37608318890814557,
                    0.2482638888888889
                ],
                "brevity_penalty": 0.45810525632318766,
                "length_ratio": 0.5615906886517944,
                "translation_length": 579,
                "reference_length": 1031
            },
            "bert": {
                "precision": 0.7939199209213257,
                "recall": 0.7795332372188568,
                "f1": 0.7866585552692413
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.48058761804826866,
            "rouge2": 0.15141955835962143,
            "rougeL": 0.27492130115424973,
            "rougeLsum": 0.27492130115424973,
            "bleu": {
                "bleu": 0.24402923098227386,
                "precisions": [
                    0.697566628041715,
                    0.4071925754060325,
                    0.22067363530778164,
                    0.12325581395348838
                ],
                "brevity_penalty": 0.823106438593841,
                "length_ratio": 0.8370514064015518,
                "translation_length": 863,
                "reference_length": 1031
            },
            "bert": {
                "precision": 0.772598147392273,
                "recall": 0.745805025100708,
                "f1": 0.7585669358571371
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.4241610738255034,
            "rouge2": 0.12113055181695828,
            "rougeL": 0.2711409395973155,
            "rougeLsum": 0.2711409395973155,
            "bleu": {
                "bleu": 0.20889316589375645,
                "precisions": [
                    0.6010362694300518,
                    0.4117647058823529,
                    0.29462738301559793,
                    0.1857638888888889
                ],
                "brevity_penalty": 0.6123196287792062,
                "length_ratio": 0.6709154113557358,
                "translation_length": 579,
                "reference_length": 863
            },
            "bert": {
                "precision": 0.733940601348877,
                "recall": 0.7392719686031342,
                "f1": 0.7364138960838318
            }
        },
        "gpt-4o": {
            "rouge1": 0.48058761804826866,
            "rouge2": 0.15141955835962143,
            "rougeL": 0.27492130115424973,
            "rougeLsum": 0.27492130115424973,
            "bleu": {
                "bleu": 0.2480930930600593,
                "precisions": [
                    0.5838991270611057,
                    0.3407766990291262,
                    0.184645286686103,
                    0.10311284046692606
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.1946697566628042,
                "translation_length": 1031,
                "reference_length": 863
            },
            "bert": {
                "precision": 0.745805025100708,
                "recall": 0.772598147392273,
                "f1": 0.7585669358571371
            }
        }
    }
}