{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.45336225596529284,
            "rouge2": 0.20652173913043478,
            "rougeL": 0.2472885032537961,
            "rougeLsum": 0.2472885032537961,
            "bleu": {
                "bleu": 0.2008799183244072,
                "precisions": [
                    0.34413965087281795,
                    0.23876871880199668,
                    0.16985845129059118,
                    0.11666666666666667
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 2.3179190751445087,
                "translation_length": 1203,
                "reference_length": 519
            },
            "bert": {
                "precision": 0.7752770781517029,
                "recall": 0.8097507655620575,
                "f1": 0.7919760942459106
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.48355263157894735,
            "rouge2": 0.20132013201320131,
            "rougeL": 0.30263157894736836,
            "rougeLsum": 0.30263157894736836,
            "bleu": {
                "bleu": 0.3014586825472371,
                "precisions": [
                    0.4953416149068323,
                    0.35303265940902023,
                    0.2632398753894081,
                    0.1794071762870515
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.2408477842003853,
                "translation_length": 644,
                "reference_length": 519
            },
            "bert": {
                "precision": 0.7554872632026672,
                "recall": 0.7667736709117889,
                "f1": 0.7609502077102661
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.45336225596529284,
            "rouge2": 0.20652173913043478,
            "rougeL": 0.2472885032537961,
            "rougeLsum": 0.2472885032537961,
            "bleu": {
                "bleu": 0.12484920686388157,
                "precisions": [
                    0.7976878612716763,
                    0.5540540540540541,
                    0.3945841392649903,
                    0.2713178294573643
                ],
                "brevity_penalty": 0.2676917692379758,
                "length_ratio": 0.4314214463840399,
                "translation_length": 519,
                "reference_length": 1203
            },
            "bert": {
                "precision": 0.8097508251667023,
                "recall": 0.7752770781517029,
                "f1": 0.791976124048233
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.47770700636942676,
            "rouge2": 0.1893617021276596,
            "rougeL": 0.29936305732484075,
            "rougeLsum": 0.29936305732484075,
            "bleu": {
                "bleu": 0.17407614440052255,
                "precisions": [
                    0.781055900621118,
                    0.5163297045101088,
                    0.3333333333333333,
                    0.21996879875195008
                ],
                "brevity_penalty": 0.4197850760542829,
                "length_ratio": 0.5353283458021613,
                "translation_length": 644,
                "reference_length": 1203
            },
            "bert": {
                "precision": 0.7884602745374044,
                "recall": 0.7502416769663492,
                "f1": 0.7681184411048889
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.48355263157894735,
            "rouge2": 0.20132013201320131,
            "rougeL": 0.30263157894736836,
            "rougeLsum": 0.30263157894736836,
            "bleu": {
                "bleu": 0.2941657236218276,
                "precisions": [
                    0.6146435452793835,
                    0.43822393822393824,
                    0.32688588007736946,
                    0.22286821705426357
                ],
                "brevity_penalty": 0.7859612530041762,
                "length_ratio": 0.8059006211180124,
                "translation_length": 519,
                "reference_length": 644
            },
            "bert": {
                "precision": 0.7667736709117889,
                "recall": 0.7554872632026672,
                "f1": 0.7609502077102661
            }
        },
        "gpt-4o": {
            "rouge1": 0.47770700636942676,
            "rouge2": 0.1893617021276596,
            "rougeL": 0.29936305732484075,
            "rougeLsum": 0.29936305732484075,
            "bleu": {
                "bleu": 0.22174873528907765,
                "precisions": [
                    0.41812136325852034,
                    0.2762063227953411,
                    0.1781848459616986,
                    0.1175
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.8680124223602483,
                "translation_length": 1203,
                "reference_length": 644
            },
            "bert": {
                "precision": 0.7502416769663492,
                "recall": 0.7884602745374044,
                "f1": 0.7681184411048889
            }
        }
    }
}