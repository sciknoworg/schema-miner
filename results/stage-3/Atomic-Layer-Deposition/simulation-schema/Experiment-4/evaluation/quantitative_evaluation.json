{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.05791019723038188,
            "rouge2": 0.026879462410751787,
            "rougeL": 0.043642467477968946,
            "rougeLsum": 0.043642467477968946,
            "bleu": {
                "bleu": 0.02107585112540149,
                "precisions": [
                    0.03649299977048428,
                    0.02594123048668503,
                    0.017451205510907005,
                    0.011943040881947635
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 22.575129533678755,
                "translation_length": 4357,
                "reference_length": 193
            },
            "bert": {
                "precision": 0.745827317237854,
                "recall": 0.8039941191673279,
                "f1": 0.7738192081451416
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.14848484848484847,
            "rouge2": 0.03951367781155015,
            "rougeL": 0.12424242424242422,
            "rougeLsum": 0.12424242424242422,
            "bleu": {
                "bleu": 0.07177685693153163,
                "precisions": [
                    0.13,
                    0.09372156505914468,
                    0.058287795992714025,
                    0.037374658158614404
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 5.699481865284974,
                "translation_length": 1100,
                "reference_length": 193
            },
            "bert": {
                "precision": 0.7793835997581482,
                "recall": 0.807540774345398,
                "f1": 0.7932124137878418
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.05791019723038188,
            "rouge2": 0.026879462410751787,
            "rougeL": 0.043642467477968946,
            "rougeLsum": 0.043642467477968946,
            "bleu": {
                "bleu": 2.0450411282921637e-10,
                "precisions": [
                    0.8238341968911918,
                    0.5885416666666666,
                    0.39790575916230364,
                    0.2736842105263158
                ],
                "brevity_penalty": 4.2661910195992437e-10,
                "length_ratio": 0.044296534312600416,
                "translation_length": 193,
                "reference_length": 4357
            },
            "bert": {
                "precision": 0.8039941191673279,
                "recall": 0.745827317237854,
                "f1": 0.7738192081451416
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.26214610276127226,
            "rouge2": 0.08044770898915705,
            "rougeL": 0.1586857742048235,
            "rougeLsum": 0.1586857742048235,
            "bleu": {
                "bleu": 0.014835619642320096,
                "precisions": [
                    0.7636363636363637,
                    0.42584167424931757,
                    0.20309653916211293,
                    0.10209662716499544
                ],
                "brevity_penalty": 0.05177183047249364,
                "length_ratio": 0.2524672940096397,
                "translation_length": 1100,
                "reference_length": 4357
            },
            "bert": {
                "precision": 0.7500139474868774,
                "recall": 0.7414622604846954,
                "f1": 0.7456599920988083
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.14848484848484847,
            "rouge2": 0.03951367781155015,
            "rougeL": 0.12424242424242422,
            "rougeLsum": 0.12424242424242422,
            "bleu": {
                "bleu": 0.003746828843718385,
                "precisions": [
                    0.7409326424870466,
                    0.5364583333333334,
                    0.33507853403141363,
                    0.21578947368421053
                ],
                "brevity_penalty": 0.009099990901591205,
                "length_ratio": 0.17545454545454545,
                "translation_length": 193,
                "reference_length": 1100
            },
            "bert": {
                "precision": 0.807540774345398,
                "recall": 0.779383659362793,
                "f1": 0.7932124137878418
            }
        },
        "gpt-4o": {
            "rouge1": 0.26214610276127226,
            "rouge2": 0.08044770898915705,
            "rougeL": 0.1586857742048235,
            "rougeLsum": 0.1586857742048235,
            "bleu": {
                "bleu": 0.07227265387553748,
                "precisions": [
                    0.19279320633463393,
                    0.10743801652892562,
                    0.05120551090700345,
                    0.02572347266881029
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 3.960909090909091,
                "translation_length": 4357,
                "reference_length": 1100
            },
            "bert": {
                "precision": 0.7414622604846954,
                "recall": 0.7500139474868774,
                "f1": 0.7456599920988083
            }
        }
    }
}