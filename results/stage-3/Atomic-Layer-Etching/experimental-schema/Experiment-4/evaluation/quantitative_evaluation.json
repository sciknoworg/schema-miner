{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.3867859600825878,
            "rouge2": 0.1847002067539628,
            "rougeL": 0.19545767377838957,
            "rougeLsum": 0.19545767377838957,
            "bleu": {
                "bleu": 0.17086767173673803,
                "precisions": [
                    0.2674641148325359,
                    0.1977022498803255,
                    0.15086206896551724,
                    0.10685194058457115
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 3.064516129032258,
                "translation_length": 2090,
                "reference_length": 682
            },
            "bert": {
                "precision": 0.7491549551486969,
                "recall": 0.7561432719230652,
                "f1": 0.7525036036968231
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.4491725768321513,
            "rouge2": 0.16587677725118483,
            "rougeL": 0.2765957446808511,
            "rougeLsum": 0.2765957446808511,
            "bleu": {
                "bleu": 0.1946183424677622,
                "precisions": [
                    0.419917864476386,
                    0.2538540596094553,
                    0.15020576131687244,
                    0.08959835221421215
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.4281524926686218,
                "translation_length": 974,
                "reference_length": 682
            },
            "bert": {
                "precision": 0.7419436872005463,
                "recall": 0.7355106174945831,
                "f1": 0.7386907637119293
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.3867859600825878,
            "rouge2": 0.1847002067539628,
            "rougeL": 0.19545767377838957,
            "rougeLsum": 0.19545767377838957,
            "bleu": {
                "bleu": 0.06653632549846837,
                "precisions": [
                    0.8196480938416423,
                    0.6064610866372981,
                    0.4632352941176471,
                    0.3284241531664212
                ],
                "brevity_penalty": 0.1268796691054282,
                "length_ratio": 0.3263157894736842,
                "translation_length": 682,
                "reference_length": 2090
            },
            "bert": {
                "precision": 0.7561432719230652,
                "recall": 0.7491549551486969,
                "f1": 0.7525036036968231
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.4031108230719378,
            "rouge2": 0.16612589227774174,
            "rougeL": 0.21775761503564484,
            "rougeLsum": 0.21775761503564484,
            "bleu": {
                "bleu": 0.08363879563754828,
                "precisions": [
                    0.6427104722792608,
                    0.3699897225077081,
                    0.19547325102880658,
                    0.10298661174047374
                ],
                "brevity_penalty": 0.31797244388232104,
                "length_ratio": 0.4660287081339713,
                "translation_length": 974,
                "reference_length": 2090
            },
            "bert": {
                "precision": 0.7371944785118103,
                "recall": 0.7259748379389445,
                "f1": 0.7314889629681905
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.4491725768321513,
            "rouge2": 0.16587677725118483,
            "rougeL": 0.2765957446808511,
            "rougeLsum": 0.2765957446808511,
            "bleu": {
                "bleu": 0.1812597113463713,
                "precisions": [
                    0.5997067448680352,
                    0.36270190895741555,
                    0.21470588235294116,
                    0.12812960235640647
                ],
                "brevity_penalty": 0.6517120259148818,
                "length_ratio": 0.7002053388090349,
                "translation_length": 682,
                "reference_length": 974
            },
            "bert": {
                "precision": 0.7355106174945831,
                "recall": 0.7419436872005463,
                "f1": 0.7386907637119293
            }
        },
        "gpt-4o": {
            "rouge1": 0.4031108230719378,
            "rouge2": 0.16612589227774174,
            "rougeL": 0.21775761503564484,
            "rougeLsum": 0.21775761503564484,
            "bleu": {
                "bleu": 0.12248226004124008,
                "precisions": [
                    0.29952153110047847,
                    0.1723312589755864,
                    0.09099616858237548,
                    0.04791566842357451
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 2.1457905544147846,
                "translation_length": 2090,
                "reference_length": 974
            },
            "bert": {
                "precision": 0.7259748379389445,
                "recall": 0.7371944983800253,
                "f1": 0.7314889430999756
            }
        }
    }
}
