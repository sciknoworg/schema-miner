{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.6263096623981373,
            "rouge2": 0.3430571761960326,
            "rougeL": 0.3934807916181607,
            "rougeLsum": 0.3934807916181607,
            "bleu": {
                "bleu": 0.4017682986745173,
                "precisions": [
                    0.5770456960680127,
                    0.4425531914893617,
                    0.3652822151224707,
                    0.279317697228145
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.363768115942029,
                "translation_length": 941,
                "reference_length": 690
            },
            "bert": {
                "precision": 0.6378699541091919,
                "recall": 0.721044679482778,
                "f1": 0.6633002360661825
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5241157556270095,
            "rouge2": 0.25806451612903225,
            "rougeL": 0.3118971061093248,
            "rougeLsum": 0.3118971061093248,
            "bleu": {
                "bleu": 0.26909290218519394,
                "precisions": [
                    0.7591836734693878,
                    0.48466257668711654,
                    0.32581967213114754,
                    0.22381930184804927
                ],
                "brevity_penalty": 0.6648703197043959,
                "length_ratio": 0.7101449275362319,
                "translation_length": 490,
                "reference_length": 690
            },
            "bert": {
                "precision": 0.7877247035503387,
                "recall": 0.7355954051017761,
                "f1": 0.7606397867202759
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.6263096623981373,
            "rouge2": 0.3430571761960326,
            "rougeL": 0.3934807916181607,
            "rougeLsum": 0.3934807916181607,
            "bleu": {
                "bleu": 0.38105378994914973,
                "precisions": [
                    0.7869565217391304,
                    0.6037735849056604,
                    0.498546511627907,
                    0.3813682678311499
                ],
                "brevity_penalty": 0.695052347616665,
                "length_ratio": 0.7332624867162593,
                "translation_length": 690,
                "reference_length": 941
            },
            "bert": {
                "precision": 0.721044659614563,
                "recall": 0.6378699541091919,
                "f1": 0.6633002360661825
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.495104895104895,
            "rouge2": 0.23562412342215988,
            "rougeL": 0.3132867132867133,
            "rougeLsum": 0.3132867132867133,
            "bleu": {
                "bleu": 0.19005546222571745,
                "precisions": [
                    0.8020408163265306,
                    0.5623721881390593,
                    0.39959016393442626,
                    0.2874743326488706
                ],
                "brevity_penalty": 0.39835641344299094,
                "length_ratio": 0.5207226354941552,
                "translation_length": 490,
                "reference_length": 941
            },
            "bert": {
                "precision": 0.7636086344718933,
                "recall": 0.7432549595832825,
                "f1": 0.7532244324684143
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.5241157556270095,
            "rouge2": 0.25806451612903225,
            "rougeL": 0.3118971061093248,
            "rougeLsum": 0.3118971061093248,
            "bleu": {
                "bleu": 0.28716093256742775,
                "precisions": [
                    0.5391304347826087,
                    0.3439767779390421,
                    0.2311046511627907,
                    0.1586608442503639
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.4081632653061225,
                "translation_length": 690,
                "reference_length": 490
            },
            "bert": {
                "precision": 0.7355954051017761,
                "recall": 0.7877247035503387,
                "f1": 0.7606397867202759
            }
        },
        "gpt-4o": {
            "rouge1": 0.495104895104895,
            "rouge2": 0.23562412342215988,
            "rougeL": 0.3132867132867133,
            "rougeLsum": 0.3132867132867133,
            "bleu": {
                "bleu": 0.24807071357219673,
                "precisions": [
                    0.41764080765143463,
                    0.2925531914893617,
                    0.20766773162939298,
                    0.14925373134328357
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.920408163265306,
                "translation_length": 941,
                "reference_length": 490
            },
            "bert": {
                "precision": 0.7432549595832825,
                "recall": 0.7636086344718933,
                "f1": 0.7532244324684143
            }
        }
    }
}
