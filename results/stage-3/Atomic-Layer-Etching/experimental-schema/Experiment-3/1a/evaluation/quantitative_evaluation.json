{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.5907335907335908,
            "rouge2": 0.2785299806576403,
            "rougeL": 0.35521235521235517,
            "rougeLsum": 0.35521235521235517,
            "bleu": {
                "bleu": 0.3629968760015332,
                "precisions": [
                    0.5828111011638317,
                    0.4157706093189964,
                    0.31928251121076234,
                    0.2244165170556553
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.3110328638497653,
                "translation_length": 1117,
                "reference_length": 852
            },
            "bert": {
                "precision": 0.7553706169128418,
                "recall": 0.7716367642084757,
                "f1": 0.7631974418958029
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5338809034907598,
            "rouge2": 0.22016460905349797,
            "rougeL": 0.3203285420944559,
            "rougeLsum": 0.3203285420944559,
            "bleu": {
                "bleu": 0.2693624019485061,
                "precisions": [
                    0.5494736842105263,
                    0.3287671232876712,
                    0.21729957805907174,
                    0.1341077085533263
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.1150234741784038,
                "translation_length": 950,
                "reference_length": 852
            },
            "bert": {
                "precision": 0.7538587053616842,
                "recall": 0.748238762219747,
                "f1": 0.7505399982134501
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.5907335907335908,
            "rouge2": 0.2785299806576403,
            "rougeL": 0.35521235521235517,
            "rougeLsum": 0.35521235521235517,
            "bleu": {
                "bleu": 0.34883370829521826,
                "precisions": [
                    0.7640845070422535,
                    0.54524089306698,
                    0.4188235294117647,
                    0.2944640753828033
                ],
                "brevity_penalty": 0.7326897964662681,
                "length_ratio": 0.7627573858549687,
                "translation_length": 852,
                "reference_length": 1117
            },
            "bert": {
                "precision": 0.7716367840766907,
                "recall": 0.7553706367810568,
                "f1": 0.7631974418958029
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.48362235067437387,
            "rouge2": 0.1583011583011583,
            "rougeL": 0.279383429672447,
            "rougeLsum": 0.279383429672447,
            "bleu": {
                "bleu": 0.24588362789681717,
                "precisions": [
                    0.6031578947368421,
                    0.3656480505795574,
                    0.23839662447257384,
                    0.14044350580781415
                ],
                "brevity_penalty": 0.838794553077097,
                "length_ratio": 0.8504923903312444,
                "translation_length": 950,
                "reference_length": 1117
            },
            "bert": {
                "precision": 0.7475498716036478,
                "recall": 0.7282712459564209,
                "f1": 0.7370175917943319
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.5338809034907598,
            "rouge2": 0.22016460905349797,
            "rougeL": 0.3203285420944559,
            "rougeLsum": 0.3203285420944559,
            "bleu": {
                "bleu": 0.26776018953027075,
                "precisions": [
                    0.6126760563380281,
                    0.36662749706227965,
                    0.24235294117647058,
                    0.14958775029446408
                ],
                "brevity_penalty": 0.8913452200645322,
                "length_ratio": 0.8968421052631579,
                "translation_length": 852,
                "reference_length": 950
            },
            "bert": {
                "precision": 0.748238762219747,
                "recall": 0.7538586854934692,
                "f1": 0.7505399982134501
            }
        },
        "gpt-4o": {
            "rouge1": 0.48362235067437387,
            "rouge2": 0.1583011583011583,
            "rougeL": 0.279383429672447,
            "rougeLsum": 0.279383429672447,
            "bleu": {
                "bleu": 0.2492537424124401,
                "precisions": [
                    0.5129811996418979,
                    0.3109318996415771,
                    0.20269058295964126,
                    0.11938958707360861
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.1757894736842105,
                "translation_length": 1117,
                "reference_length": 950
            },
            "bert": {
                "precision": 0.7282712459564209,
                "recall": 0.7475498716036478,
                "f1": 0.7370175917943319
            }
        }
    }
}