{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.7086614173228346,
            "rouge2": 0.5614430665163471,
            "rougeL": 0.6119235095613049,
            "rougeLsum": 0.6119235095613049,
            "bleu": {
                "bleu": 0.544767781916314,
                "precisions": [
                    0.6413373860182371,
                    0.5649087221095335,
                    0.5177664974619289,
                    0.4695121951219512
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.4201438848920864,
                "translation_length": 987,
                "reference_length": 695
            },
            "bert": {
                "precision": 0.8163330256938934,
                "recall": 0.8200543522834778,
                "f1": 0.8181690871715546
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.6293558606124604,
            "rouge2": 0.45079365079365086,
            "rougeL": 0.4054910242872228,
            "rougeLsum": 0.4054910242872228,
            "bleu": {
                "bleu": 0.46219216940895363,
                "precisions": [
                    0.5658986175115207,
                    0.4806273062730627,
                    0.4312096029547553,
                    0.38909426987060997
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.5611510791366907,
                "translation_length": 1085,
                "reference_length": 695
            },
            "bert": {
                "precision": 0.8450781404972076,
                "recall": 0.853988915681839,
                "f1": 0.849510133266449
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.7086614173228346,
            "rouge2": 0.5614430665163471,
            "rougeL": 0.6119235095613049,
            "rougeLsum": 0.6119235095613049,
            "bleu": {
                "bleu": 0.5085758016929021,
                "precisions": [
                    0.9107913669064748,
                    0.8025936599423631,
                    0.7359307359307359,
                    0.6676300578034682
                ],
                "brevity_penalty": 0.6569522875053407,
                "length_ratio": 0.7041540020263425,
                "translation_length": 695,
                "reference_length": 987
            },
            "bert": {
                "precision": 0.8200543522834778,
                "recall": 0.8163330256938934,
                "f1": 0.8181690871715546
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.6021897810218977,
            "rouge2": 0.3528336380255941,
            "rougeL": 0.354014598540146,
            "rougeLsum": 0.354014598540146,
            "bleu": {
                "bleu": 0.4681148839331725,
                "precisions": [
                    0.6967741935483871,
                    0.5138376383763837,
                    0.4053554939981533,
                    0.33086876155268025
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.099290780141844,
                "translation_length": 1085,
                "reference_length": 987
            },
            "bert": {
                "precision": 0.7971510291099548,
                "recall": 0.7849767208099365,
                "f1": 0.7908296783765157
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.6293558606124604,
            "rouge2": 0.45079365079365086,
            "rougeL": 0.4054910242872228,
            "rougeLsum": 0.4054910242872228,
            "bleu": {
                "bleu": 0.4120031623548352,
                "precisions": [
                    0.883453237410072,
                    0.7507204610951008,
                    0.6738816738816739,
                    0.6083815028901735
                ],
                "brevity_penalty": 0.5705519352887747,
                "length_ratio": 0.6405529953917051,
                "translation_length": 695,
                "reference_length": 1085
            },
            "bert": {
                "precision": 0.853988915681839,
                "recall": 0.8450781404972076,
                "f1": 0.849510133266449
            }
        },
        "gpt-4o": {
            "rouge1": 0.6021897810218977,
            "rouge2": 0.3528336380255941,
            "rougeL": 0.354014598540146,
            "rougeLsum": 0.354014598540146,
            "bleu": {
                "bleu": 0.46601870353940117,
                "precisions": [
                    0.7659574468085106,
                    0.5649087221095335,
                    0.44568527918781725,
                    0.3638211382113821
                ],
                "brevity_penalty": 0.9054793743183969,
                "length_ratio": 0.9096774193548387,
                "translation_length": 987,
                "reference_length": 1085
            },
            "bert": {
                "precision": 0.7849767208099365,
                "recall": 0.7971510291099548,
                "f1": 0.7908296783765157
            }
        }
    }
}