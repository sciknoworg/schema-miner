{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.43312101910828027,
            "rouge2": 0.3104181431608788,
            "rougeL": 0.33687190375088466,
            "rougeLsum": 0.33687190375088466,
            "bleu": {
                "bleu": 0.23105722558719732,
                "precisions": [
                    0.2924861321230459,
                    0.2462159434914228,
                    0.21352852094901564,
                    0.18535353535353535
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 3.1228346456692915,
                "translation_length": 1983,
                "reference_length": 635
            },
            "bert": {
                "precision": 0.7788709700107574,
                "recall": 0.7912895083427429,
                "f1": 0.7848659753799438
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.48648648648648646,
            "rouge2": 0.27436823104693137,
            "rougeL": 0.27387387387387385,
            "rougeLsum": 0.27387387387387385,
            "bleu": {
                "bleu": 0.262083041699829,
                "precisions": [
                    0.3713892709766162,
                    0.2807983482450103,
                    0.2327823691460055,
                    0.1943487250172295
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 2.289763779527559,
                "translation_length": 1454,
                "reference_length": 635
            },
            "bert": {
                "precision": 0.7997671365737915,
                "recall": 0.794599324464798,
                "f1": 0.7969821989536285
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.43312101910828027,
            "rouge2": 0.3104181431608788,
            "rougeL": 0.33687190375088466,
            "rougeLsum": 0.33687190375088466,
            "bleu": {
                "bleu": 0.0865032144943049,
                "precisions": [
                    0.9133858267716536,
                    0.7697160883280757,
                    0.6682464454976303,
                    0.5806962025316456
                ],
                "brevity_penalty": 0.11969186316021682,
                "length_ratio": 0.3202218860312658,
                "translation_length": 635,
                "reference_length": 1983
            },
            "bert": {
                "precision": 0.7912895083427429,
                "recall": 0.7788709104061127,
                "f1": 0.7848658859729767
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5831960461285008,
            "rouge2": 0.28257284222100054,
            "rougeL": 0.30203185063152116,
            "rougeLsum": 0.30203185063152116,
            "bleu": {
                "bleu": 0.3353251546347361,
                "precisions": [
                    0.8184319119669876,
                    0.573296627666896,
                    0.40771349862258954,
                    0.2832529290144728
                ],
                "brevity_penalty": 0.6950135522443927,
                "length_ratio": 0.7332324760463943,
                "translation_length": 1454,
                "reference_length": 1983
            },
            "bert": {
                "precision": 0.7768379926681519,
                "recall": 0.7478679299354554,
                "f1": 0.7620132803916931
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.48648648648648646,
            "rouge2": 0.27436823104693137,
            "rougeL": 0.27387387387387385,
            "rougeLsum": 0.27387387387387385,
            "bleu": {
                "bleu": 0.16545187667320105,
                "precisions": [
                    0.8503937007874016,
                    0.6435331230283912,
                    0.5339652448657188,
                    0.4462025316455696
                ],
                "brevity_penalty": 0.27533581536485807,
                "length_ratio": 0.43672627235213207,
                "translation_length": 635,
                "reference_length": 1454
            },
            "bert": {
                "precision": 0.7945992648601532,
                "recall": 0.7997671365737915,
                "f1": 0.7969821393489838
            }
        },
        "gpt-4o": {
            "rouge1": 0.5831960461285008,
            "rouge2": 0.28257284222100054,
            "rougeL": 0.30203185063152116,
            "rougeLsum": 0.30203185063152116,
            "bleu": {
                "bleu": 0.35366726613225,
                "precisions": [
                    0.600100857286939,
                    0.4202825428859738,
                    0.29883897021706207,
                    0.20757575757575758
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.3638239339752407,
                "translation_length": 1983,
                "reference_length": 1454
            },
            "bert": {
                "precision": 0.7478679180145263,
                "recall": 0.7768379926681519,
                "f1": 0.7620132684707641
            }
        }
    }
}
