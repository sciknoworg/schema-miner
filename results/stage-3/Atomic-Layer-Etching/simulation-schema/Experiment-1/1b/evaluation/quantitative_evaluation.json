{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.613095238095238,
            "rouge2": 0.37176938369781315,
            "rougeL": 0.43055555555555547,
            "rougeLsum": 0.43055555555555547,
            "bleu": {
                "bleu": 0.38119317211742104,
                "precisions": [
                    0.5454545454545454,
                    0.4240218380345769,
                    0.3360655737704918,
                    0.2716499544211486
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.5151515151515151,
                "translation_length": 1100,
                "reference_length": 726
            },
            "bert": {
                "precision": 0.8009208142757416,
                "recall": 0.8192964494228363,
                "f1": 0.8099983930587769
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5988304093567252,
            "rouge2": 0.27198124267291907,
            "rougeL": 0.3906432748538012,
            "rougeLsum": 0.3906432748538012,
            "bleu": {
                "bleu": 0.3998153873985562,
                "precisions": [
                    0.6509090909090909,
                    0.4538834951456311,
                    0.3353584447144593,
                    0.25790754257907544
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.1363636363636365,
                "translation_length": 825,
                "reference_length": 726
            },
            "bert": {
                "precision": 0.8073621392250061,
                "recall": 0.7992516756057739,
                "f1": 0.8032448887825012
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.613095238095238,
            "rouge2": 0.37176938369781315,
            "rougeL": 0.43055555555555547,
            "rougeLsum": 0.43055555555555547,
            "bleu": {
                "bleu": 0.3452865140023291,
                "precisions": [
                    0.8264462809917356,
                    0.6427586206896552,
                    0.5096685082872928,
                    0.41217150760719223
                ],
                "brevity_penalty": 0.5974100710831303,
                "length_ratio": 0.66,
                "translation_length": 726,
                "reference_length": 1100
            },
            "bert": {
                "precision": 0.8192964494228363,
                "recall": 0.8009208142757416,
                "f1": 0.8099983930587769
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5365853658536585,
            "rouge2": 0.2072336265884653,
            "rougeL": 0.28487804878048784,
            "rougeLsum": 0.28487804878048784,
            "bleu": {
                "bleu": 0.26374650330588967,
                "precisions": [
                    0.7781818181818182,
                    0.49150485436893204,
                    0.28797083839611176,
                    0.16666666666666666
                ],
                "brevity_penalty": 0.7165313105737893,
                "length_ratio": 0.75,
                "translation_length": 825,
                "reference_length": 1100
            },
            "bert": {
                "precision": 0.7923972805341085,
                "recall": 0.7617280880610148,
                "f1": 0.7766861716906229
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.5988304093567252,
            "rouge2": 0.27198124267291907,
            "rougeL": 0.3906432748538012,
            "rougeLsum": 0.3906432748538012,
            "bleu": {
                "bleu": 0.3965179573229474,
                "precisions": [
                    0.7396694214876033,
                    0.5158620689655172,
                    0.3812154696132597,
                    0.29322268326417705
                ],
                "brevity_penalty": 0.8725252928694237,
                "length_ratio": 0.88,
                "translation_length": 726,
                "reference_length": 825
            },
            "bert": {
                "precision": 0.7992516756057739,
                "recall": 0.8073621392250061,
                "f1": 0.8032448887825012
            }
        },
        "gpt-4o": {
            "rouge1": 0.5365853658536585,
            "rouge2": 0.2072336265884653,
            "rougeL": 0.28487804878048784,
            "rougeLsum": 0.28487804878048784,
            "bleu": {
                "bleu": 0.27594015556356194,
                "precisions": [
                    0.5836363636363636,
                    0.3685168334849864,
                    0.21584699453551912,
                    0.12488605287146765
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.3333333333333333,
                "translation_length": 1100,
                "reference_length": 825
            },
            "bert": {
                "precision": 0.7617280880610148,
                "recall": 0.7923972805341085,
                "f1": 0.7766861716906229
            }
        }
    }
}
