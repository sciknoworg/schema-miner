{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.6276595744680851,
            "rouge2": 0.4140030441400304,
            "rougeL": 0.3890577507598784,
            "rougeLsum": 0.3890577507598784,
            "bleu": {
                "bleu": 0.4077408158583729,
                "precisions": [
                    0.5421768707482993,
                    0.4411164057181756,
                    0.3726158038147139,
                    0.3101567825494206
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.6333333333333333,
                "translation_length": 1470,
                "reference_length": 900
            },
            "bert": {
                "precision": 0.7487295269966125,
                "recall": 0.7673783500989279,
                "f1": 0.7578022877375284
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5322175732217574,
            "rouge2": 0.23470243084660522,
            "rougeL": 0.2912133891213389,
            "rougeLsum": 0.2912133891213389,
            "bleu": {
                "bleu": 0.308445024212522,
                "precisions": [
                    0.5119225037257824,
                    0.35197613721103654,
                    0.25970149253731345,
                    0.19342793129200897
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.491111111111111,
                "translation_length": 1342,
                "reference_length": 900
            },
            "bert": {
                "precision": 0.7432117660840353,
                "recall": 0.7636592785517374,
                "f1": 0.7532804012298584
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.6276595744680851,
            "rouge2": 0.4140030441400304,
            "rougeL": 0.3890577507598784,
            "rougeLsum": 0.3890577507598784,
            "bleu": {
                "bleu": 0.3537423816445573,
                "precisions": [
                    0.8855555555555555,
                    0.7208008898776418,
                    0.60913140311804,
                    0.5072463768115942
                ],
                "brevity_penalty": 0.530819450562014,
                "length_ratio": 0.6122448979591837,
                "translation_length": 900,
                "reference_length": 1470
            },
            "bert": {
                "precision": 0.7673783500989279,
                "recall": 0.7487295269966125,
                "f1": 0.7578022877375284
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5721889554224883,
            "rouge2": 0.2305129913391073,
            "rougeL": 0.2594810379241517,
            "rougeLsum": 0.2594810379241517,
            "bleu": {
                "bleu": 0.32946675105058315,
                "precisions": [
                    0.7585692995529061,
                    0.47576435495898584,
                    0.2783582089552239,
                    0.1717699775952203
                ],
                "brevity_penalty": 0.9090274113068365,
                "length_ratio": 0.9129251700680272,
                "translation_length": 1342,
                "reference_length": 1470
            },
            "bert": {
                "precision": 0.7516695618629455,
                "recall": 0.7223128080368042,
                "f1": 0.7361306309700012
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.5322175732217574,
            "rouge2": 0.23470243084660522,
            "rougeL": 0.2912133891213389,
            "rougeLsum": 0.2912133891213389,
            "bleu": {
                "bleu": 0.28160466512797955,
                "precisions": [
                    0.7633333333333333,
                    0.525027808676307,
                    0.38752783964365256,
                    0.2887402452619844
                ],
                "brevity_penalty": 0.6119460762152967,
                "length_ratio": 0.6706408345752608,
                "translation_length": 900,
                "reference_length": 1342
            },
            "bert": {
                "precision": 0.7636592785517374,
                "recall": 0.7432117660840353,
                "f1": 0.7532804012298584
            }
        },
        "gpt-4o": {
            "rouge1": 0.5721889554224883,
            "rouge2": 0.2305129913391073,
            "rougeL": 0.2594810379241517,
            "rougeLsum": 0.2594810379241517,
            "bleu": {
                "bleu": 0.33084719439185634,
                "precisions": [
                    0.6925170068027211,
                    0.4343090537780803,
                    0.25408719346049047,
                    0.15678254942058623
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.0953800298062593,
                "translation_length": 1470,
                "reference_length": 1342
            },
            "bert": {
                "precision": 0.7223128080368042,
                "recall": 0.7516695618629455,
                "f1": 0.7361306309700012
            }
        }
    }
}