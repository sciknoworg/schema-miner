{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.6135389888603257,
            "rouge2": 0.47038626609442064,
            "rougeL": 0.5072836332476436,
            "rougeLsum": 0.5072836332476436,
            "bleu": {
                "bleu": 0.41548301342177146,
                "precisions": [
                    0.4912891986062718,
                    0.4309623430962343,
                    0.3928820655966504,
                    0.35824022346368717
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.8709256844850066,
                "translation_length": 1435,
                "reference_length": 767
            },
            "bert": {
                "precision": 0.746963620185852,
                "recall": 0.7841647466023763,
                "f1": 0.7648356954256693
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5872340425531914,
            "rouge2": 0.3070362473347548,
            "rougeL": 0.3914893617021276,
            "rougeLsum": 0.3914893617021276,
            "bleu": {
                "bleu": 0.4188663932791064,
                "precisions": [
                    0.6248736097067745,
                    0.45951417004048584,
                    0.3657548125633232,
                    0.29310344827586204
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.2894393741851369,
                "translation_length": 989,
                "reference_length": 767
            },
            "bert": {
                "precision": 0.7667935490608215,
                "recall": 0.7831571102142334,
                "f1": 0.7748284538586935
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.6135389888603257,
            "rouge2": 0.47038626609442064,
            "rougeL": 0.5072836332476436,
            "rougeLsum": 0.5072836332476436,
            "bleu": {
                "bleu": 0.3256626010668817,
                "precisions": [
                    0.9191655801825294,
                    0.8067885117493473,
                    0.7359477124183007,
                    0.6714659685863874
                ],
                "brevity_penalty": 0.418563911741224,
                "length_ratio": 0.5344947735191637,
                "translation_length": 767,
                "reference_length": 1435
            },
            "bert": {
                "precision": 0.7841647664705912,
                "recall": 0.746963640054067,
                "f1": 0.7648356954256693
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5771916214119472,
            "rouge2": 0.26884226884226886,
            "rougeL": 0.3366951124903025,
            "rougeLsum": 0.3366951124903025,
            "bleu": {
                "bleu": 0.32074163734457045,
                "precisions": [
                    0.8099089989888777,
                    0.5809716599190283,
                    0.4275582573454914,
                    0.31947261663286003
                ],
                "brevity_penalty": 0.6370159616245659,
                "length_ratio": 0.689198606271777,
                "translation_length": 989,
                "reference_length": 1435
            },
            "bert": {
                "precision": 0.8040013710657755,
                "recall": 0.7805273731549581,
                "f1": 0.7920020421346029
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.5872340425531914,
            "rouge2": 0.3070362473347548,
            "rougeL": 0.3914893617021276,
            "rougeLsum": 0.3914893617021276,
            "bleu": {
                "bleu": 0.40454392916759974,
                "precisions": [
                    0.8057366362451108,
                    0.5926892950391645,
                    0.4718954248366013,
                    0.3782722513089005
                ],
                "brevity_penalty": 0.7486831810629567,
                "length_ratio": 0.775530839231547,
                "translation_length": 767,
                "reference_length": 989
            },
            "bert": {
                "precision": 0.7831571102142334,
                "recall": 0.7667935490608215,
                "f1": 0.7748284538586935
            }
        },
        "gpt-4o": {
            "rouge1": 0.5771916214119472,
            "rouge2": 0.26884226884226886,
            "rougeL": 0.3366951124903025,
            "rougeLsum": 0.3366951124903025,
            "bleu": {
                "bleu": 0.34685206793894324,
                "precisions": [
                    0.5581881533101045,
                    0.400278940027894,
                    0.2944870900209351,
                    0.21997206703910616
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.4509605662285137,
                "translation_length": 1435,
                "reference_length": 989
            },
            "bert": {
                "precision": 0.7805273731549581,
                "recall": 0.8040013710657755,
                "f1": 0.7920020421346029
            }
        }
    }
}
