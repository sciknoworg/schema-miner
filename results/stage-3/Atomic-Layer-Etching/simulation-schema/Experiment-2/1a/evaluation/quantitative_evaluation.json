{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.590851334180432,
            "rouge2": 0.44147582697201015,
            "rougeL": 0.4447268106734435,
            "rougeLsum": 0.4447268106734435,
            "bleu": {
                "bleu": 0.380632725469269,
                "precisions": [
                    0.4610966057441253,
                    0.3960292580982236,
                    0.35912179822268686,
                    0.3200836820083682
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.9560776302349336,
                "translation_length": 1915,
                "reference_length": 979
            },
            "bert": {
                "precision": 0.7876906593640646,
                "recall": 0.8048631548881531,
                "f1": 0.7959561149279276
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.6162332545311269,
            "rouge2": 0.35201262825572227,
            "rougeL": 0.43183609141055945,
            "rougeLsum": 0.43183609141055945,
            "bleu": {
                "bleu": 0.4149037939447559,
                "precisions": [
                    0.5819250551065394,
                    0.44191176470588234,
                    0.37527593818984545,
                    0.3070692194403535
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.390194075587334,
                "translation_length": 1361,
                "reference_length": 979
            },
            "bert": {
                "precision": 0.8005970120429993,
                "recall": 0.7767429749170939,
                "f1": 0.7883896032969157
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.590851334180432,
            "rouge2": 0.44147582697201015,
            "rougeL": 0.4447268106734435,
            "rougeLsum": 0.4447268106734435,
            "bleu": {
                "bleu": 0.2864170029702456,
                "precisions": [
                    0.9019407558733401,
                    0.7750511247443763,
                    0.7031729785056294,
                    0.6270491803278688
                ],
                "brevity_penalty": 0.38439768270965446,
                "length_ratio": 0.5112271540469974,
                "translation_length": 979,
                "reference_length": 1915
            },
            "bert": {
                "precision": 0.8048631548881531,
                "recall": 0.7876906593640646,
                "f1": 0.7959561149279276
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.6028490028490029,
            "rouge2": 0.29092983456930976,
            "rougeL": 0.3521367521367521,
            "rougeLsum": 0.3521367521367521,
            "bleu": {
                "bleu": 0.3309995963804722,
                "precisions": [
                    0.8302718589272594,
                    0.5845588235294118,
                    0.41133186166298746,
                    0.30633284241531666
                ],
                "brevity_penalty": 0.6656084880805445,
                "length_ratio": 0.7107049608355092,
                "translation_length": 1361,
                "reference_length": 1915
            },
            "bert": {
                "precision": 0.7937865406274796,
                "recall": 0.7642260044813156,
                "f1": 0.7785349041223526
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.6162332545311269,
            "rouge2": 0.35201262825572227,
            "rougeL": 0.43183609141055945,
            "rougeLsum": 0.43183609141055945,
            "bleu": {
                "bleu": 0.39061674368707416,
                "precisions": [
                    0.8089887640449438,
                    0.614519427402863,
                    0.5220061412487206,
                    0.42725409836065575
                ],
                "brevity_penalty": 0.6769254870375497,
                "length_ratio": 0.7193240264511389,
                "translation_length": 979,
                "reference_length": 1361
            },
            "bert": {
                "precision": 0.7767429749170939,
                "recall": 0.8005970120429993,
                "f1": 0.7883896032969157
            }
        },
        "gpt-4o": {
            "rouge1": 0.6028490028490029,
            "rouge2": 0.29092983456930976,
            "rougeL": 0.3521367521367521,
            "rougeLsum": 0.3521367521367521,
            "bleu": {
                "bleu": 0.3533127297666435,
                "precisions": [
                    0.5900783289817232,
                    0.4153605015673981,
                    0.2922111866178777,
                    0.2175732217573222
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.4070536370315945,
                "translation_length": 1915,
                "reference_length": 1361
            },
            "bert": {
                "precision": 0.7642260044813156,
                "recall": 0.7937865406274796,
                "f1": 0.7785349041223526
            }
        }
    }
}