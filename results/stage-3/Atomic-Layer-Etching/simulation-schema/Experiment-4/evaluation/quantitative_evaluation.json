{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.4266487213997308,
            "rouge2": 0.2641509433962264,
            "rougeL": 0.2799461641991925,
            "rougeLsum": 0.2799461641991925,
            "bleu": {
                "bleu": 0.2066250053152522,
                "precisions": [
                    0.2909275215408008,
                    0.2297160243407708,
                    0.1872146118721461,
                    0.14568527918781726
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 3.0030441400304415,
                "translation_length": 1973,
                "reference_length": 657
            },
            "bert": {
                "precision": 0.7656331360340118,
                "recall": 0.7906194925308228,
                "f1": 0.7778454124927521
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.3695054945054945,
            "rouge2": 0.15268225584594222,
            "rougeL": 0.21153846153846154,
            "rougeLsum": 0.21153846153846154,
            "bleu": {
                "bleu": 0.16353112503072417,
                "precisions": [
                    0.2686804451510334,
                    0.18292682926829268,
                    0.14058355437665782,
                    0.1035031847133758
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 2.872146118721461,
                "translation_length": 1887,
                "reference_length": 657
            },
            "bert": {
                "precision": 0.7761487364768982,
                "recall": 0.7786999046802521,
                "f1": 0.7774125039577484
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.4266487213997308,
            "rouge2": 0.2641509433962264,
            "rougeL": 0.2799461641991925,
            "rougeLsum": 0.2799461641991925,
            "bleu": {
                "bleu": 0.0838487336609863,
                "precisions": [
                    0.8736681887366818,
                    0.6905487804878049,
                    0.5633587786259542,
                    0.43883792048929665
                ],
                "brevity_penalty": 0.13492393010930195,
                "length_ratio": 0.3329954384186518,
                "translation_length": 657,
                "reference_length": 1973
            },
            "bert": {
                "precision": 0.7906195223331451,
                "recall": 0.7656331360340118,
                "f1": 0.7778454422950745
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5447830101569714,
            "rouge2": 0.17652495378927913,
            "rougeL": 0.2603878116343491,
            "rougeLsum": 0.2603878116343491,
            "bleu": {
                "bleu": 0.28022881515164183,
                "precisions": [
                    0.6894541600423953,
                    0.41251325556733826,
                    0.23342175066312998,
                    0.11146496815286625
                ],
                "brevity_penalty": 0.955447953947386,
                "length_ratio": 0.9564115560060821,
                "translation_length": 1887,
                "reference_length": 1973
            },
            "bert": {
                "precision": 0.750402182340622,
                "recall": 0.7196732262770335,
                "f1": 0.7346405883630117
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.3695054945054945,
            "rouge2": 0.15268225584594222,
            "rougeL": 0.21153846153846154,
            "rougeLsum": 0.21153846153846154,
            "bleu": {
                "bleu": 0.07234226329354948,
                "precisions": [
                    0.771689497716895,
                    0.5259146341463414,
                    0.40458015267175573,
                    0.2981651376146789
                ],
                "brevity_penalty": 0.15379324881866732,
                "length_ratio": 0.3481717011128776,
                "translation_length": 657,
                "reference_length": 1887
            },
            "bert": {
                "precision": 0.7786999046802521,
                "recall": 0.7761487364768982,
                "f1": 0.7774125039577484
            }
        },
        "gpt-4o": {
            "rouge1": 0.5447830101569714,
            "rouge2": 0.17652495378927913,
            "rougeL": 0.2603878116343491,
            "rougeLsum": 0.2603878116343491,
            "bleu": {
                "bleu": 0.28050170448644834,
                "precisions": [
                    0.6594019260010137,
                    0.3945233265720081,
                    0.22323693556570268,
                    0.1065989847715736
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.0455749867514574,
                "translation_length": 1973,
                "reference_length": 1887
            },
            "bert": {
                "precision": 0.7196732262770335,
                "recall": 0.7504021922747294,
                "f1": 0.7346405883630117
            }
        }
    }
}
