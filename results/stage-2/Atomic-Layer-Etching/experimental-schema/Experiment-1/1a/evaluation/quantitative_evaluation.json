{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.5671321160042965,
            "rouge2": 0.29709364908503766,
            "rougeL": 0.30075187969924816,
            "rougeLsum": 0.30075187969924816,
            "bleu": {
                "bleu": 0.328662848242146,
                "precisions": [
                    0.4981167608286252,
                    0.37323279924599434,
                    0.29150943396226414,
                    0.21529745042492918
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.5827123695976155,
                "translation_length": 1062,
                "reference_length": 671
            },
            "bert": {
                "precision": 0.7739356756210327,
                "recall": 0.7568947076797485,
                "f1": 0.7652957737445831
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.4149933065595716,
            "rouge2": 0.16375838926174496,
            "rougeL": 0.28380187416332,
            "rougeLsum": 0.28380187416332,
            "bleu": {
                "bleu": 0.20028865105041394,
                "precisions": [
                    0.4568469505178366,
                    0.24308755760368664,
                    0.14763552479815456,
                    0.09815242494226328
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.2950819672131149,
                "translation_length": 869,
                "reference_length": 671
            },
            "bert": {
                "precision": 0.7637430131435394,
                "recall": 0.7418428361415863,
                "f1": 0.7524949312210083
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.5671321160042965,
            "rouge2": 0.29709364908503766,
            "rougeL": 0.30075187969924816,
            "rougeLsum": 0.30075187969924816,
            "bleu": {
                "bleu": 0.2906981739171563,
                "precisions": [
                    0.7883755588673621,
                    0.591044776119403,
                    0.4618834080717489,
                    0.3413173652694611
                ],
                "brevity_penalty": 0.5583817729691485,
                "length_ratio": 0.6318267419962336,
                "translation_length": 671,
                "reference_length": 1062
            },
            "bert": {
                "precision": 0.7568947076797485,
                "recall": 0.7739356756210327,
                "f1": 0.7652957737445831
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.41942604856512145,
            "rouge2": 0.15265486725663718,
            "rougeL": 0.2229580573951435,
            "rougeLsum": 0.2229580573951435,
            "bleu": {
                "bleu": 0.21237458283945243,
                "precisions": [
                    0.6248561565017261,
                    0.35023041474654376,
                    0.19377162629757785,
                    0.11662817551963048
                ],
                "brevity_penalty": 0.8008397924573523,
                "length_ratio": 0.8182674199623352,
                "translation_length": 869,
                "reference_length": 1062
            },
            "bert": {
                "precision": 0.7485119303067526,
                "recall": 0.7464023033777872,
                "f1": 0.747401773929596
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.4149933065595716,
            "rouge2": 0.16375838926174496,
            "rougeL": 0.28380187416332,
            "rougeLsum": 0.28380187416332,
            "bleu": {
                "bleu": 0.19320707180555166,
                "precisions": [
                    0.5916542473919523,
                    0.31492537313432833,
                    0.19133034379671152,
                    0.12724550898203593
                ],
                "brevity_penalty": 0.7444705627876546,
                "length_ratio": 0.7721518987341772,
                "translation_length": 671,
                "reference_length": 869
            },
            "bert": {
                "precision": 0.7418428361415863,
                "recall": 0.7637430131435394,
                "f1": 0.7524949312210083
            }
        },
        "gpt-4o": {
            "rouge1": 0.41942604856512145,
            "rouge2": 0.15265486725663718,
            "rougeL": 0.2229580573951435,
            "rougeLsum": 0.2229580573951435,
            "bleu": {
                "bleu": 0.2169279867346155,
                "precisions": [
                    0.5112994350282486,
                    0.2865221489161169,
                    0.15849056603773584,
                    0.09537299338999056
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.2220943613348676,
                "translation_length": 1062,
                "reference_length": 869
            },
            "bert": {
                "precision": 0.7464023033777872,
                "recall": 0.7485119303067526,
                "f1": 0.747401773929596
            }
        }
    }
}