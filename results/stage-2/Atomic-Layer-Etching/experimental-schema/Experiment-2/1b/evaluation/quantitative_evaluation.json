{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.5602240896358543,
            "rouge2": 0.2837078651685393,
            "rougeL": 0.3865546218487395,
            "rougeLsum": 0.3865546218487395,
            "bleu": {
                "bleu": 0.32361017831682104,
                "precisions": [
                    0.5143929912390488,
                    0.37092731829573933,
                    0.27728983688833125,
                    0.20728643216080403
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.4396396396396396,
                "translation_length": 799,
                "reference_length": 555
            },
            "bert": {
                "precision": 0.7737822234630585,
                "recall": 0.7461093068122864,
                "f1": 0.7595516741275787
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.4176570458404074,
            "rouge2": 0.1567291311754685,
            "rougeL": 0.27164685908319186,
            "rougeLsum": 0.27164685908319186,
            "bleu": {
                "bleu": 0.21892267368258092,
                "precisions": [
                    0.45271317829457364,
                    0.2562111801242236,
                    0.16951788491446346,
                    0.11682242990654206
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.162162162162162,
                "translation_length": 645,
                "reference_length": 555
            },
            "bert": {
                "precision": 0.7348472476005554,
                "recall": 0.7015005350112915,
                "f1": 0.7177851796150208
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.5602240896358543,
            "rouge2": 0.2837078651685393,
            "rougeL": 0.3865546218487395,
            "rougeLsum": 0.3865546218487395,
            "bleu": {
                "bleu": 0.3004018680248499,
                "precisions": [
                    0.7405405405405405,
                    0.5342960288808665,
                    0.3996383363471971,
                    0.29891304347826086
                ],
                "brevity_penalty": 0.6442685481021041,
                "length_ratio": 0.6946182728410513,
                "translation_length": 555,
                "reference_length": 799
            },
            "bert": {
                "precision": 0.7461093068122864,
                "recall": 0.7737822234630585,
                "f1": 0.7595516741275787
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.4240601503759399,
            "rouge2": 0.13574660633484165,
            "rougeL": 0.25263157894736843,
            "rougeLsum": 0.25263157894736843,
            "bleu": {
                "bleu": 0.22110304034163866,
                "precisions": [
                    0.641860465116279,
                    0.37732919254658387,
                    0.208398133748056,
                    0.12305295950155763
                ],
                "brevity_penalty": 0.787604128842117,
                "length_ratio": 0.8072590738423029,
                "translation_length": 645,
                "reference_length": 799
            },
            "bert": {
                "precision": 0.7612356543540955,
                "recall": 0.7563152015209198,
                "f1": 0.7586588263511658
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.4176570458404074,
            "rouge2": 0.1567291311754685,
            "rougeL": 0.27164685908319186,
            "rougeLsum": 0.27164685908319186,
            "bleu": {
                "bleu": 0.21641919028486226,
                "precisions": [
                    0.5261261261261261,
                    0.29783393501805056,
                    0.19710669077757687,
                    0.1358695652173913
                ],
                "brevity_penalty": 0.8503033063369505,
                "length_ratio": 0.8604651162790697,
                "translation_length": 555,
                "reference_length": 645
            },
            "bert": {
                "precision": 0.7015005350112915,
                "recall": 0.7348472476005554,
                "f1": 0.7177851796150208
            }
        },
        "gpt-4o": {
            "rouge1": 0.4240601503759399,
            "rouge2": 0.13574660633484165,
            "rougeL": 0.25263157894736843,
            "rougeLsum": 0.25263157894736843,
            "bleu": {
                "bleu": 0.22651885679491043,
                "precisions": [
                    0.5181476846057572,
                    0.30451127819548873,
                    0.16813048933500627,
                    0.0992462311557789
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.2387596899224806,
                "translation_length": 799,
                "reference_length": 645
            },
            "bert": {
                "precision": 0.7563152015209198,
                "recall": 0.7612356543540955,
                "f1": 0.7586588263511658
            }
        }
    }
}
