{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.5801376597836775,
            "rouge2": 0.37241379310344824,
            "rougeL": 0.3893805309734514,
            "rougeLsum": 0.3893805309734514,
            "bleu": {
                "bleu": 0.3302085220188023,
                "precisions": [
                    0.466268146883006,
                    0.36752136752136755,
                    0.2968349016253208,
                    0.23373287671232876
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.8587301587301588,
                "translation_length": 1171,
                "reference_length": 630
            },
            "bert": {
                "precision": 0.7704366445541382,
                "recall": 0.799063116312027,
                "f1": 0.7843997478485107
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.492836676217765,
            "rouge2": 0.20095693779904306,
            "rougeL": 0.2808022922636103,
            "rougeLsum": 0.2808022922636103,
            "bleu": {
                "bleu": 0.25375152645918325,
                "precisions": [
                    0.40931780366056575,
                    0.28309741881765194,
                    0.22,
                    0.16263552960800667
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.907936507936508,
                "translation_length": 1202,
                "reference_length": 630
            },
            "bert": {
                "precision": 0.7822695076465607,
                "recall": 0.7976451516151428,
                "f1": 0.7898570001125336
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.5801376597836775,
            "rouge2": 0.37241379310344824,
            "rougeL": 0.3893805309734514,
            "rougeLsum": 0.3893805309734514,
            "bleu": {
                "bleu": 0.2603406235952218,
                "precisions": [
                    0.8666666666666667,
                    0.6836248012718601,
                    0.552547770700637,
                    0.4354066985645933
                ],
                "brevity_penalty": 0.42369977231192846,
                "length_ratio": 0.53800170794193,
                "translation_length": 630,
                "reference_length": 1171
            },
            "bert": {
                "precision": 0.799063116312027,
                "recall": 0.7704366445541382,
                "f1": 0.7843997478485107
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.543939393939394,
            "rouge2": 0.18057663125948406,
            "rougeL": 0.27121212121212124,
            "rougeLsum": 0.27121212121212124,
            "bleu": {
                "bleu": 0.29089091607895406,
                "precisions": [
                    0.64891846921797,
                    0.3938384679433805,
                    0.23166666666666666,
                    0.12093411175979983
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.026473099914603,
                "translation_length": 1202,
                "reference_length": 1171
            },
            "bert": {
                "precision": 0.7588567286729813,
                "recall": 0.7387370765209198,
                "f1": 0.7486444264650345
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.492836676217765,
            "rouge2": 0.20095693779904306,
            "rougeL": 0.2808022922636103,
            "rougeLsum": 0.2808022922636103,
            "bleu": {
                "bleu": 0.19550336160772014,
                "precisions": [
                    0.780952380952381,
                    0.5405405405405406,
                    0.42038216560509556,
                    0.31100478468899523
                ],
                "brevity_penalty": 0.4033556871390214,
                "length_ratio": 0.5241264559068219,
                "translation_length": 630,
                "reference_length": 1202
            },
            "bert": {
                "precision": 0.7976451516151428,
                "recall": 0.7822695076465607,
                "f1": 0.7898570001125336
            }
        },
        "gpt-4o": {
            "rouge1": 0.543939393939394,
            "rouge2": 0.18057663125948406,
            "rougeL": 0.27121212121212124,
            "rougeLsum": 0.27121212121212124,
            "bleu": {
                "bleu": 0.29080039124765056,
                "precisions": [
                    0.6660973526900086,
                    0.4042735042735043,
                    0.23781009409751924,
                    0.12414383561643835
                ],
                "brevity_penalty": 0.9738742407834267,
                "length_ratio": 0.9742096505823628,
                "translation_length": 1171,
                "reference_length": 1202
            },
            "bert": {
                "precision": 0.7387370765209198,
                "recall": 0.7588567286729813,
                "f1": 0.7486444264650345
            }
        }
    }
}
