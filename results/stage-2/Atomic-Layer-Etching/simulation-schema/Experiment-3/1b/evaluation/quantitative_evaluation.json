{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.6592865928659287,
            "rouge2": 0.49321824907521583,
            "rougeL": 0.5510455104551046,
            "rougeLsum": 0.5510455104551046,
            "bleu": {
                "bleu": 0.4761362555931368,
                "precisions": [
                    0.5879781420765028,
                    0.5010940919037199,
                    0.44687842278203727,
                    0.39035087719298245
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.5149006622516556,
                "translation_length": 915,
                "reference_length": 604
            },
            "bert": {
                "precision": 0.7710691094398499,
                "recall": 0.7806812822818756,
                "f1": 0.7757036089897156
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.6892655367231638,
            "rouge2": 0.45042492917847027,
            "rougeL": 0.48870056497175146,
            "rougeLsum": 0.48870056497175146,
            "bleu": {
                "bleu": 0.5648384687796044,
                "precisions": [
                    0.733044733044733,
                    0.5939306358381503,
                    0.5137481910274964,
                    0.45507246376811594
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.1473509933774835,
                "translation_length": 693,
                "reference_length": 604
            },
            "bert": {
                "precision": 0.8206386566162109,
                "recall": 0.8354840874671936,
                "f1": 0.8279716670513153
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.6592865928659287,
            "rouge2": 0.49321824907521583,
            "rougeL": 0.5510455104551046,
            "rougeLsum": 0.5510455104551046,
            "bleu": {
                "bleu": 0.4313846215249982,
                "precisions": [
                    0.890728476821192,
                    0.7595356550580431,
                    0.6777408637873754,
                    0.5923460898502496
                ],
                "brevity_penalty": 0.5975599519301035,
                "length_ratio": 0.6601092896174864,
                "translation_length": 604,
                "reference_length": 915
            },
            "bert": {
                "precision": 0.7806812524795532,
                "recall": 0.7710691392421722,
                "f1": 0.7757036089897156
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5720876585928489,
            "rouge2": 0.31445086705202313,
            "rougeL": 0.3460207612456747,
            "rougeLsum": 0.3460207612456747,
            "bleu": {
                "bleu": 0.3710148052369753,
                "precisions": [
                    0.7864357864357865,
                    0.5722543352601156,
                    0.4341534008683068,
                    0.3492753623188406
                ],
                "brevity_penalty": 0.7258976004290173,
                "length_ratio": 0.7573770491803279,
                "translation_length": 693,
                "reference_length": 915
            },
            "bert": {
                "precision": 0.7687937617301941,
                "recall": 0.7581619918346405,
                "f1": 0.763356477022171
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.6892655367231638,
            "rouge2": 0.45042492917847027,
            "rougeL": 0.48870056497175146,
            "rougeLsum": 0.48870056497175146,
            "bleu": {
                "bleu": 0.5594558983622415,
                "precisions": [
                    0.8410596026490066,
                    0.681592039800995,
                    0.5897009966777409,
                    0.5224625623960066
                ],
                "brevity_penalty": 0.8629910201185378,
                "length_ratio": 0.8715728715728716,
                "translation_length": 604,
                "reference_length": 693
            },
            "bert": {
                "precision": 0.8354840874671936,
                "recall": 0.8206386566162109,
                "f1": 0.8279716670513153
            }
        },
        "gpt-4o": {
            "rouge1": 0.5720876585928489,
            "rouge2": 0.31445086705202313,
            "rougeL": 0.3460207612456747,
            "rougeLsum": 0.3460207612456747,
            "bleu": {
                "bleu": 0.386900481281487,
                "precisions": [
                    0.5956284153005464,
                    0.43326039387308535,
                    0.32858707557502737,
                    0.2642543859649123
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.3203463203463204,
                "translation_length": 915,
                "reference_length": 693
            },
            "bert": {
                "precision": 0.7581619918346405,
                "recall": 0.7687937617301941,
                "f1": 0.763356477022171
            }
        }
    }
}
