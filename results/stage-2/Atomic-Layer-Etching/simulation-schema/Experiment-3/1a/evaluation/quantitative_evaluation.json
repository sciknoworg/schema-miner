{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.6123959296947271,
            "rouge2": 0.428174235403151,
            "rougeL": 0.46993524514338575,
            "rougeLsum": 0.46993524514338575,
            "bleu": {
                "bleu": 0.40107512352508295,
                "precisions": [
                    0.51015625,
                    0.4292415949960907,
                    0.37167449139280123,
                    0.3179326546593579
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.755829903978052,
                "translation_length": 1280,
                "reference_length": 729
            },
            "bert": {
                "precision": 0.6788419882456461,
                "recall": 0.7666304508845011,
                "f1": 0.7156166632970175
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5634920634920634,
            "rouge2": 0.3180914512922466,
            "rougeL": 0.33928571428571436,
            "rougeLsum": 0.33928571428571436,
            "bleu": {
                "bleu": 0.35490260322431505,
                "precisions": [
                    0.5209059233449478,
                    0.3870967741935484,
                    0.3106457242582897,
                    0.25327510917030566
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.5747599451303156,
                "translation_length": 1148,
                "reference_length": 729
            },
            "bert": {
                "precision": 0.6933692097663879,
                "recall": 0.735595166683197,
                "f1": 0.7112086216608683
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.6123959296947271,
            "rouge2": 0.428174235403151,
            "rougeL": 0.46993524514338575,
            "rougeLsum": 0.46993524514338575,
            "bleu": {
                "bleu": 0.3310099516949483,
                "precisions": [
                    0.8957475994513031,
                    0.7541208791208791,
                    0.6533700137551581,
                    0.559228650137741
                ],
                "brevity_penalty": 0.4696207128645796,
                "length_ratio": 0.56953125,
                "translation_length": 729,
                "reference_length": 1280
            },
            "bert": {
                "precision": 0.7666304508845011,
                "recall": 0.6788419882456461,
                "f1": 0.7156166632970175
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5936777178103315,
            "rouge2": 0.27644787644787644,
            "rougeL": 0.2713955281418658,
            "rougeLsum": 0.2713955281418658,
            "bleu": {
                "bleu": 0.3700408605313746,
                "precisions": [
                    0.759581881533101,
                    0.5056669572798606,
                    0.33158813263525305,
                    0.2331877729257642
                ],
                "brevity_penalty": 0.8913816730689998,
                "length_ratio": 0.896875,
                "translation_length": 1148,
                "reference_length": 1280
            },
            "bert": {
                "precision": 0.7547915726900101,
                "recall": 0.7247970551252365,
                "f1": 0.739448755979538
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.5634920634920634,
            "rouge2": 0.3180914512922466,
            "rougeL": 0.33928571428571436,
            "rougeLsum": 0.33928571428571436,
            "bleu": {
                "bleu": 0.3148005482944089,
                "precisions": [
                    0.8203017832647462,
                    0.6098901098901099,
                    0.4896836313617607,
                    0.39944903581267216
                ],
                "brevity_penalty": 0.5628399650655166,
                "length_ratio": 0.6350174216027874,
                "translation_length": 729,
                "reference_length": 1148
            },
            "bert": {
                "precision": 0.735595166683197,
                "recall": 0.6933692097663879,
                "f1": 0.7112086216608683
            }
        },
        "gpt-4o": {
            "rouge1": 0.5936777178103315,
            "rouge2": 0.27644787644787644,
            "rougeL": 0.2713955281418658,
            "rougeLsum": 0.2713955281418658,
            "bleu": {
                "bleu": 0.37227105308050323,
                "precisions": [
                    0.68125,
                    0.45347928068803756,
                    0.297339593114241,
                    0.2090837901331245
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.1149825783972125,
                "translation_length": 1280,
                "reference_length": 1148
            },
            "bert": {
                "precision": 0.7247970402240753,
                "recall": 0.7547915726900101,
                "f1": 0.7394487410783768
            }
        }
    }
}