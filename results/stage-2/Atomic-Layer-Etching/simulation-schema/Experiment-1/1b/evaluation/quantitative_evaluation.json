{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.6216216216216216,
            "rouge2": 0.3724604966139955,
            "rougeL": 0.4459459459459459,
            "rougeLsum": 0.4459459459459459,
            "bleu": {
                "bleu": 0.4115043285568987,
                "precisions": [
                    0.6068281938325991,
                    0.4564498346196251,
                    0.3631346578366446,
                    0.2850828729281768
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.3431952662721893,
                "translation_length": 908,
                "reference_length": 676
            },
            "bert": {
                "precision": 0.8023724853992462,
                "recall": 0.8188126981258392,
                "f1": 0.8104745149612427
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5910931174089069,
            "rouge2": 0.24627875507442493,
            "rougeL": 0.3724696356275303,
            "rougeLsum": 0.3724696356275303,
            "bleu": {
                "bleu": 0.43769869675038786,
                "precisions": [
                    0.7,
                    0.4992526158445441,
                    0.37425149700598803,
                    0.2908545727136432
                ],
                "brevity_penalty": 0.9910847547087005,
                "length_ratio": 0.9911242603550295,
                "translation_length": 670,
                "reference_length": 676
            },
            "bert": {
                "precision": 0.8097876012325287,
                "recall": 0.8051437735557556,
                "f1": 0.8073920011520386
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.6216216216216216,
            "rouge2": 0.3724604966139955,
            "rougeL": 0.4459459459459459,
            "rougeLsum": 0.4459459459459459,
            "bleu": {
                "bleu": 0.3923852903050705,
                "precisions": [
                    0.8150887573964497,
                    0.6133333333333333,
                    0.48813056379821956,
                    0.3833580980683507
                ],
                "brevity_penalty": 0.7094996566800219,
                "length_ratio": 0.7444933920704846,
                "translation_length": 676,
                "reference_length": 908
            },
            "bert": {
                "precision": 0.8188126981258392,
                "recall": 0.8023724853992462,
                "f1": 0.8104745149612427
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5135453474676089,
            "rouge2": 0.1912632821723731,
            "rougeL": 0.2850412249705536,
            "rougeLsum": 0.2850412249705536,
            "bleu": {
                "bleu": 0.25314377831443236,
                "precisions": [
                    0.7686567164179104,
                    0.484304932735426,
                    0.2874251497005988,
                    0.15892053973013492
                ],
                "brevity_penalty": 0.7010164816504751,
                "length_ratio": 0.737885462555066,
                "translation_length": 670,
                "reference_length": 908
            },
            "bert": {
                "precision": 0.7861143946647644,
                "recall": 0.7699040472507477,
                "f1": 0.7779240012168884
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.5910931174089069,
            "rouge2": 0.24627875507442493,
            "rougeL": 0.3724696356275303,
            "rougeLsum": 0.3724696356275303,
            "bleu": {
                "bleu": 0.43770741579695027,
                "precisions": [
                    0.6937869822485208,
                    0.4948148148148148,
                    0.37091988130563797,
                    0.28826151560178304
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.008955223880597,
                "translation_length": 676,
                "reference_length": 670
            },
            "bert": {
                "precision": 0.8051437735557556,
                "recall": 0.8097876012325287,
                "f1": 0.8073920011520386
            }
        },
        "gpt-4o": {
            "rouge1": 0.5135453474676089,
            "rouge2": 0.1912632821723731,
            "rougeL": 0.2850412249705536,
            "rougeLsum": 0.2850412249705536,
            "bleu": {
                "bleu": 0.26630072891639767,
                "precisions": [
                    0.5671806167400881,
                    0.3572216097023153,
                    0.2119205298013245,
                    0.11712707182320442
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.355223880597015,
                "translation_length": 908,
                "reference_length": 670
            },
            "bert": {
                "precision": 0.7699040472507477,
                "recall": 0.7861143946647644,
                "f1": 0.7779240012168884
            }
        }
    }
}
