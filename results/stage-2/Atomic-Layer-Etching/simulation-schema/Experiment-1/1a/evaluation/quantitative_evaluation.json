{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.5800000000000001,
            "rouge2": 0.3366733466933868,
            "rougeL": 0.382,
            "rougeLsum": 0.382,
            "bleu": {
                "bleu": 0.3324507469771323,
                "precisions": [
                    0.47510917030567684,
                    0.36451048951048953,
                    0.2983377077865267,
                    0.23642732049036777
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.8174603174603174,
                "translation_length": 1145,
                "reference_length": 630
            },
            "bert": {
                "precision": 0.766535758972168,
                "recall": 0.7977369725704193,
                "f1": 0.7817247807979584
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.4715162138475022,
            "rouge2": 0.21949078138718175,
            "rougeL": 0.26468010517090274,
            "rougeLsum": 0.26468010517090274,
            "bleu": {
                "bleu": 0.22945620699335836,
                "precisions": [
                    0.36075949367088606,
                    0.2512315270935961,
                    0.2,
                    0.1529245947850599
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 2.257142857142857,
                "translation_length": 1422,
                "reference_length": 630
            },
            "bert": {
                "precision": 0.7805849015712738,
                "recall": 0.7816735506057739,
                "f1": 0.7811284363269806
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.5800000000000001,
            "rouge2": 0.3366733466933868,
            "rougeL": 0.382,
            "rougeLsum": 0.382,
            "bleu": {
                "bleu": 0.2670792663241086,
                "precisions": [
                    0.8634920634920635,
                    0.6629570747217806,
                    0.5429936305732485,
                    0.430622009569378
                ],
                "brevity_penalty": 0.44155163268139297,
                "length_ratio": 0.5502183406113537,
                "translation_length": 630,
                "reference_length": 1145
            },
            "bert": {
                "precision": 0.7977369725704193,
                "recall": 0.766535758972168,
                "f1": 0.7817247807979584
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5414599574769667,
            "rouge2": 0.19588360539389638,
            "rougeL": 0.27072997873848337,
            "rougeLsum": 0.27072997873848337,
            "bleu": {
                "bleu": 0.2772238839415929,
                "precisions": [
                    0.5829817158931083,
                    0.35608726249120337,
                    0.22183098591549297,
                    0.12825933756166313
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.2419213973799126,
                "translation_length": 1422,
                "reference_length": 1145
            },
            "bert": {
                "precision": 0.7552349120378494,
                "recall": 0.7396280318498611,
                "f1": 0.747226893901825
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.4715162138475022,
            "rouge2": 0.21949078138718175,
            "rougeL": 0.26468010517090274,
            "rougeLsum": 0.26468010517090274,
            "bleu": {
                "bleu": 0.1475251663732244,
                "precisions": [
                    0.8142857142857143,
                    0.5675675675675675,
                    0.45222929936305734,
                    0.34609250398724084
                ],
                "brevity_penalty": 0.28446562545044835,
                "length_ratio": 0.4430379746835443,
                "translation_length": 630,
                "reference_length": 1422
            },
            "bert": {
                "precision": 0.7816735506057739,
                "recall": 0.7805849015712738,
                "f1": 0.7811284363269806
            }
        },
        "gpt-4o": {
            "rouge1": 0.5414599574769667,
            "rouge2": 0.19588360539389638,
            "rougeL": 0.27072997873848337,
            "rougeLsum": 0.27072997873848337,
            "bleu": {
                "bleu": 0.27037756841939214,
                "precisions": [
                    0.7240174672489083,
                    0.4423076923076923,
                    0.2755905511811024,
                    0.159369527145359
                ],
                "brevity_penalty": 0.7851178874495489,
                "length_ratio": 0.8052039381153305,
                "translation_length": 1145,
                "reference_length": 1422
            },
            "bert": {
                "precision": 0.7396280318498611,
                "recall": 0.7552349120378494,
                "f1": 0.747226893901825
            }
        }
    }
}