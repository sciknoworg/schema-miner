{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.5769944341372912,
            "rouge2": 0.42007434944237915,
            "rougeL": 0.45454545454545453,
            "rougeLsum": 0.45454545454545453,
            "bleu": {
                "bleu": 0.37372797970308447,
                "precisions": [
                    0.45590433482810166,
                    0.3911742707554226,
                    0.35104790419161674,
                    0.31161048689138576
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.9792899408284024,
                "translation_length": 1338,
                "reference_length": 676
            },
            "bert": {
                "precision": 0.7706964313983917,
                "recall": 0.7951924204826355,
                "f1": 0.7827514111995697
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.6275395033860045,
            "rouge2": 0.37556561085972856,
            "rougeL": 0.42437923250564336,
            "rougeLsum": 0.42437923250564336,
            "bleu": {
                "bleu": 0.44470984050498014,
                "precisions": [
                    0.5974842767295597,
                    0.472193074501574,
                    0.40441176470588236,
                    0.34279705573080965
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.4112426035502958,
                "translation_length": 954,
                "reference_length": 676
            },
            "bert": {
                "precision": 0.8209932446479797,
                "recall": 0.8336747884750366,
                "f1": 0.8272850811481476
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.5769944341372912,
            "rouge2": 0.42007434944237915,
            "rougeL": 0.45454545454545453,
            "rougeLsum": 0.45454545454545453,
            "bleu": {
                "bleu": 0.2781268066641641,
                "precisions": [
                    0.9023668639053254,
                    0.7748148148148148,
                    0.6958456973293768,
                    0.6181277860326895
                ],
                "brevity_penalty": 0.37557768657466967,
                "length_ratio": 0.5052316890881914,
                "translation_length": 676,
                "reference_length": 1338
            },
            "bert": {
                "precision": 0.7951923906803131,
                "recall": 0.7706964313983917,
                "f1": 0.7827513813972473
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5974025974025974,
            "rouge2": 0.2991869918699187,
            "rougeL": 0.38636363636363635,
            "rougeLsum": 0.38636363636363635,
            "bleu": {
                "bleu": 0.3462819840485106,
                "precisions": [
                    0.8144654088050315,
                    0.5907660020986358,
                    0.44432773109243695,
                    0.33648790746582546
                ],
                "brevity_penalty": 0.6686358257015949,
                "length_ratio": 0.7130044843049327,
                "translation_length": 954,
                "reference_length": 1338
            },
            "bert": {
                "precision": 0.7848552862803141,
                "recall": 0.7577766180038452,
                "f1": 0.7708646257718405
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.6275395033860045,
            "rouge2": 0.37556561085972856,
            "rougeL": 0.42437923250564336,
            "rougeLsum": 0.42437923250564336,
            "bleu": {
                "bleu": 0.4162552019424369,
                "precisions": [
                    0.8431952662721893,
                    0.6666666666666666,
                    0.5712166172106825,
                    0.48439821693907875
                ],
                "brevity_penalty": 0.6628261081262831,
                "length_ratio": 0.7085953878406709,
                "translation_length": 676,
                "reference_length": 954
            },
            "bert": {
                "precision": 0.8336748480796814,
                "recall": 0.8209932446479797,
                "f1": 0.8272851407527924
            }
        },
        "gpt-4o": {
            "rouge1": 0.5974025974025974,
            "rouge2": 0.2991869918699187,
            "rougeL": 0.38636363636363635,
            "rougeLsum": 0.38636363636363635,
            "bleu": {
                "bleu": 0.36909327195990205,
                "precisions": [
                    0.5807174887892377,
                    0.42109199700822736,
                    0.3166167664670659,
                    0.2397003745318352
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.4025157232704402,
                "translation_length": 1338,
                "reference_length": 954
            },
            "bert": {
                "precision": 0.7577766180038452,
                "recall": 0.7848552862803141,
                "f1": 0.7708646257718405
            }
        }
    }
}