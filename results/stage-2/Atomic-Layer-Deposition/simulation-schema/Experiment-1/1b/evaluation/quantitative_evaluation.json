{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.5162200282087448,
            "rouge2": 0.2461103253182461,
            "rougeL": 0.3187588152327221,
            "rougeLsum": 0.3187588152327221,
            "bleu": {
                "bleu": 0.2511204677648085,
                "precisions": [
                    0.42921348314606744,
                    0.3048368953880765,
                    0.21396396396396397,
                    0.14205186020293123
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.909871244635193,
                "translation_length": 890,
                "reference_length": 466
            },
            "bert": {
                "precision": 0.766581267118454,
                "recall": 0.7992011904716492,
                "f1": 0.7825162410736084
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.4057971014492754,
            "rouge2": 0.11954765751211631,
            "rougeL": 0.27053140096618356,
            "rougeLsum": 0.27053140096618356,
            "bleu": {
                "bleu": 0.2216825129884351,
                "precisions": [
                    0.3753180661577608,
                    0.25987261146496815,
                    0.19387755102040816,
                    0.1277139208173691
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.6866952789699572,
                "translation_length": 786,
                "reference_length": 466
            },
            "bert": {
                "precision": 0.7467493712902069,
                "recall": 0.7651970982551575,
                "f1": 0.7554774880409241
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.5162200282087448,
            "rouge2": 0.2461103253182461,
            "rougeL": 0.3187588152327221,
            "rougeLsum": 0.3187588152327221,
            "bleu": {
                "bleu": 0.19337604734057445,
                "precisions": [
                    0.8197424892703863,
                    0.5827956989247312,
                    0.40948275862068967,
                    0.27213822894168466
                ],
                "brevity_penalty": 0.40257605452360024,
                "length_ratio": 0.5235955056179775,
                "translation_length": 466,
                "reference_length": 890
            },
            "bert": {
                "precision": 0.7992012202739716,
                "recall": 0.766581267118454,
                "f1": 0.7825162708759308
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.4951219512195122,
            "rouge2": 0.1687041564792176,
            "rougeL": 0.28048780487804875,
            "rougeLsum": 0.28048780487804875,
            "bleu": {
                "bleu": 0.27175998324652084,
                "precisions": [
                    0.688295165394402,
                    0.4089171974522293,
                    0.2385204081632653,
                    0.13793103448275862
                ],
                "brevity_penalty": 0.8760645341584792,
                "length_ratio": 0.8831460674157303,
                "translation_length": 786,
                "reference_length": 890
            },
            "bert": {
                "precision": 0.7768060564994812,
                "recall": 0.75739453236262,
                "f1": 0.7668618758519491
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.4057971014492754,
            "rouge2": 0.11954765751211631,
            "rougeL": 0.27053140096618356,
            "rougeLsum": 0.27053140096618356,
            "bleu": {
                "bleu": 0.18841328090054255,
                "precisions": [
                    0.6330472103004292,
                    0.43870967741935485,
                    0.3275862068965517,
                    0.2159827213822894
                ],
                "brevity_penalty": 0.5032363799708001,
                "length_ratio": 0.5928753180661578,
                "translation_length": 466,
                "reference_length": 786
            },
            "bert": {
                "precision": 0.7651970982551575,
                "recall": 0.7467493712902069,
                "f1": 0.7554774880409241
            }
        },
        "gpt-4o": {
            "rouge1": 0.4951219512195122,
            "rouge2": 0.1687041564792176,
            "rougeL": 0.28048780487804875,
            "rougeLsum": 0.28048780487804875,
            "bleu": {
                "bleu": 0.2738954555755812,
                "precisions": [
                    0.6078651685393258,
                    0.3610798650168729,
                    0.21058558558558557,
                    0.12175873731679819
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.1323155216284988,
                "translation_length": 890,
                "reference_length": 786
            },
            "bert": {
                "precision": 0.757394552230835,
                "recall": 0.7768060564994812,
                "f1": 0.7668618758519491
            }
        }
    }
}