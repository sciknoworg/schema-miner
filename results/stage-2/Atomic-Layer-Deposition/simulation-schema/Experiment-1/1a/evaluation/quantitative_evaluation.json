{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.22091310751104565,
            "rouge2": 0.10635155096011815,
            "rougeL": 0.1826215022091311,
            "rougeLsum": 0.1826215022091311,
            "bleu": {
                "bleu": 0.09852862888226833,
                "precisions": [
                    0.15935114503816794,
                    0.11174785100286533,
                    0.08508604206500955,
                    0.06220095693779904
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 4.851851851851852,
                "translation_length": 1048,
                "reference_length": 216
            },
            "bert": {
                "precision": 0.7746278047561646,
                "recall": 0.8052478432655334,
                "f1": 0.7896410822868347
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.2080536912751678,
            "rouge2": 0.07744107744107744,
            "rougeL": 0.1409395973154362,
            "rougeLsum": 0.1409395973154362,
            "bleu": {
                "bleu": 0.08534433348597018,
                "precisions": [
                    0.15392254220456802,
                    0.10139165009940358,
                    0.06965174129353234,
                    0.04880478087649402
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 4.662037037037037,
                "translation_length": 1007,
                "reference_length": 216
            },
            "bert": {
                "precision": 0.7579973340034485,
                "recall": 0.7493795156478882,
                "f1": 0.7536637783050537
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.22091310751104565,
            "rouge2": 0.10635155096011815,
            "rougeL": 0.1826215022091311,
            "rougeLsum": 0.1826215022091311,
            "bleu": {
                "bleu": 0.010210382754840285,
                "precisions": [
                    0.7731481481481481,
                    0.5441860465116279,
                    0.4158878504672897,
                    0.3051643192488263
                ],
                "brevity_penalty": 0.02124036598442216,
                "length_ratio": 0.20610687022900764,
                "translation_length": 216,
                "reference_length": 1048
            },
            "bert": {
                "precision": 0.8052478432655334,
                "recall": 0.7746278047561646,
                "f1": 0.7896410822868347
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.42540904716073147,
            "rouge2": 0.12536162005785922,
            "rougeL": 0.24061597690086622,
            "rougeLsum": 0.24061597690086622,
            "bleu": {
                "bleu": 0.2254781189424349,
                "precisions": [
                    0.5819265143992055,
                    0.33399602385685884,
                    0.16716417910447762,
                    0.09362549800796813
                ],
                "brevity_penalty": 0.9601027250017417,
                "length_ratio": 0.9608778625954199,
                "translation_length": 1007,
                "reference_length": 1048
            },
            "bert": {
                "precision": 0.7504509389400482,
                "recall": 0.7523570358753204,
                "f1": 0.7504904866218567
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.2080536912751678,
            "rouge2": 0.07744107744107744,
            "rougeL": 0.1409395973154362,
            "rougeLsum": 0.1409395973154362,
            "bleu": {
                "bleu": 0.010273835857261767,
                "precisions": [
                    0.7175925925925926,
                    0.4744186046511628,
                    0.32710280373831774,
                    0.2300469483568075
                ],
                "brevity_penalty": 0.02568014799743382,
                "length_ratio": 0.21449851042701093,
                "translation_length": 216,
                "reference_length": 1007
            },
            "bert": {
                "precision": 0.7493795156478882,
                "recall": 0.7579973936080933,
                "f1": 0.7536638379096985
            }
        },
        "gpt-4o": {
            "rouge1": 0.42540904716073147,
            "rouge2": 0.12536162005785922,
            "rougeL": 0.24061597690086622,
            "rougeLsum": 0.24061597690086622,
            "bleu": {
                "bleu": 0.22564697841298864,
                "precisions": [
                    0.5591603053435115,
                    0.3209169054441261,
                    0.16061185468451242,
                    0.08995215311004785
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.0407149950347567,
                "translation_length": 1048,
                "reference_length": 1007
            },
            "bert": {
                "precision": 0.7523570507764816,
                "recall": 0.7504509389400482,
                "f1": 0.7504904866218567
            }
        }
    }
}