{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.1836734693877551,
            "rouge2": 0.061403508771929814,
            "rougeL": 0.13411078717201164,
            "rougeLsum": 0.13411078717201164,
            "bleu": {
                "bleu": 0.09853130679806647,
                "precisions": [
                    0.18739054290718038,
                    0.12795793163891322,
                    0.07719298245614035,
                    0.050921861281826165
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 4.623481781376518,
                "translation_length": 1142,
                "reference_length": 247
            },
            "bert": {
                "precision": 0.7453424334526062,
                "recall": 0.7958410382270813,
                "f1": 0.7697644233703613
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.20959147424511546,
            "rouge2": 0.08912655971479501,
            "rougeL": 0.15985790408525755,
            "rougeLsum": 0.15985790408525755,
            "bleu": {
                "bleu": 0.12347450196541365,
                "precisions": [
                    0.21920668058455114,
                    0.16091954022988506,
                    0.09832635983263599,
                    0.06701570680628273
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 3.8785425101214575,
                "translation_length": 958,
                "reference_length": 247
            },
            "bert": {
                "precision": 0.7408084869384766,
                "recall": 0.7979398965835571,
                "f1": 0.7683135867118835
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.1836734693877551,
            "rouge2": 0.061403508771929814,
            "rougeL": 0.13411078717201164,
            "rougeLsum": 0.13411078717201164,
            "bleu": {
                "bleu": 0.012216989145479265,
                "precisions": [
                    0.8663967611336032,
                    0.5934959349593496,
                    0.35918367346938773,
                    0.23770491803278687
                ],
                "brevity_penalty": 0.02668958722070137,
                "length_ratio": 0.21628721541155868,
                "translation_length": 247,
                "reference_length": 1142
            },
            "bert": {
                "precision": 0.7958409786224365,
                "recall": 0.7453424334526062,
                "f1": 0.7697643637657166
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5051449953227316,
            "rouge2": 0.17806935332708523,
            "rougeL": 0.2675397567820393,
            "rougeLsum": 0.2675397567820393,
            "bleu": {
                "bleu": 0.24167852224892805,
                "precisions": [
                    0.6899791231732777,
                    0.4117032392894462,
                    0.20606694560669456,
                    0.1256544502617801
                ],
                "brevity_penalty": 0.8252517350101662,
                "length_ratio": 0.8388791593695272,
                "translation_length": 958,
                "reference_length": 1142
            },
            "bert": {
                "precision": 0.7722028344869614,
                "recall": 0.7320030480623245,
                "f1": 0.7509086728096008
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.20959147424511546,
            "rouge2": 0.08912655971479501,
            "rougeL": 0.15985790408525755,
            "rougeLsum": 0.15985790408525755,
            "bleu": {
                "bleu": 0.0270445550086904,
                "precisions": [
                    0.8502024291497976,
                    0.6260162601626016,
                    0.3836734693877551,
                    0.26229508196721313
                ],
                "brevity_penalty": 0.056216638334661666,
                "length_ratio": 0.2578288100208768,
                "translation_length": 247,
                "reference_length": 958
            },
            "bert": {
                "precision": 0.7979398965835571,
                "recall": 0.7408084869384766,
                "f1": 0.7683135867118835
            }
        },
        "gpt-4o": {
            "rouge1": 0.5051449953227316,
            "rouge2": 0.17806935332708523,
            "rougeL": 0.2675397567820393,
            "rougeLsum": 0.2675397567820393,
            "bleu": {
                "bleu": 0.2456072641322032,
                "precisions": [
                    0.5788091068301225,
                    0.3453111305872042,
                    0.17280701754385966,
                    0.10535557506584724
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.1920668058455115,
                "translation_length": 1142,
                "reference_length": 958
            },
            "bert": {
                "precision": 0.7320030480623245,
                "recall": 0.7722028493881226,
                "f1": 0.7509086728096008
            }
        }
    }
}