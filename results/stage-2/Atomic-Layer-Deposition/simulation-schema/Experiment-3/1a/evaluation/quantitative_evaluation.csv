Reference,Comparison,rouge1,rouge2,rougeL,rougeLsum,bleu_bleu,bleu_precisions,bleu_brevity_penalty,bleu_length_ratio,bleu_translation_length,bleu_reference_length,bert_precision,bert_recall,bert_f1
gpt-4-turbo,gpt-4o,0.183673469,0.061403509,0.134110787,0.134110787,0.098531307,"[0.18739054290718038, 0.12795793163891322, 0.07719298245614035, 0.050921861281826165]",1,4.623481781,1142,247,0.745342433,0.795841038,0.769764423
,meta-llama-3.1-8b-instruct,0.209591474,0.08912656,0.159857904,0.159857904,0.123474502,"[0.21920668058455114, 0.16091954022988506, 0.09832635983263599, 0.06701570680628273]",1,3.87854251,958,247,0.740808487,0.797939897,0.768313587
gpt-4o,gpt-4-turbo,0.183673469,0.061403509,0.134110787,0.134110787,0.012216989,"[0.8663967611336032, 0.5934959349593496, 0.35918367346938773, 0.23770491803278687]",0.026689587,0.216287215,247,1142,0.795840979,0.745342433,0.769764364
,meta-llama-3.1-8b-instruct,0.505144995,0.178069353,0.267539757,0.267539757,0.241678522,"[0.6899791231732777, 0.4117032392894462, 0.20606694560669456, 0.1256544502617801]",0.825251735,0.838879159,958,1142,0.772202834,0.732003048,0.750908673
meta-llama-3.1-8b-instruct,gpt-4-turbo,0.209591474,0.08912656,0.159857904,0.159857904,0.027044555,"[0.8502024291497976, 0.6260162601626016, 0.3836734693877551, 0.26229508196721313]",0.056216638,0.25782881,247,958,0.797939897,0.740808487,0.768313587
,gpt-4o,0.505144995,0.178069353,0.267539757,0.267539757,0.245607264,"[0.5788091068301225, 0.3453111305872042, 0.17280701754385966, 0.10535557506584724]",1,1.192066806,1142,958,0.732003048,0.772202849,0.750908673
