Reference,Comparison,rouge1,rouge2,rougeL,rougeLsum,bleu_bleu,bleu_precisions,bleu_brevity_penalty,bleu_length_ratio,bleu_translation_length,bleu_reference_length,bert_precision,bert_recall,bert_f1
gpt-4-turbo,gpt-4o,0.219665272,0.100628931,0.138075314,0.138075314,0.098940166,"[0.1644088669950739, 0.12076401725200246, 0.08323057953144267, 0.05798889574336829]",1,5.468013468,1624,297,0.756990016,0.798793316,0.777330101
,meta-llama-3.1-8b-instruct,0.266318538,0.083989501,0.203655352,0.203655352,0.208461421,"[0.3881453154875717, 0.2662835249042146, 0.1727447216890595, 0.10576923076923077]",1,1.760942761,523,297,0.791052282,0.794408917,0.792727053
gpt-4o,gpt-4-turbo,0.219665272,0.100628931,0.138075314,0.138075314,0.006231165,"[0.898989898989899, 0.6621621621621622, 0.4576271186440678, 0.3197278911564626]",0.011470079,0.182881773,297,1624,0.798793316,0.756990016,0.777330101
,meta-llama-3.1-8b-instruct,0.324423963,0.09787627,0.188018433,0.188018433,0.042778985,"[0.7820267686424475, 0.4789272030651341, 0.2706333973128599, 0.15]",0.121825873,0.322044335,523,1624,0.783076406,0.744599134,0.763335854
meta-llama-3.1-8b-instruct,gpt-4-turbo,0.266318538,0.083989501,0.203655352,0.203655352,0.171890308,"[0.6835016835016835, 0.46959459459459457, 0.3050847457627119, 0.1870748299319728]",0.467225737,0.567877629,297,523,0.794408917,0.791052282,0.792727053
,gpt-4o,0.324423963,0.09787627,0.188018433,0.188018433,0.112865096,"[0.2518472906403941, 0.15403573629081946, 0.08692971639950678, 0.048118445404071564]",1,3.105162524,1624,523,0.744599134,0.783076406,0.763335854
