{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.21966527196652716,
            "rouge2": 0.10062893081761007,
            "rougeL": 0.13807531380753138,
            "rougeLsum": 0.13807531380753138,
            "bleu": {
                "bleu": 0.09894016637819421,
                "precisions": [
                    0.1644088669950739,
                    0.12076401725200246,
                    0.08323057953144267,
                    0.05798889574336829
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 5.468013468013468,
                "translation_length": 1624,
                "reference_length": 297
            },
            "bert": {
                "precision": 0.7569900155067444,
                "recall": 0.7987933158874512,
                "f1": 0.7773301005363464
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.2663185378590079,
            "rouge2": 0.08398950131233596,
            "rougeL": 0.20365535248041775,
            "rougeLsum": 0.20365535248041775,
            "bleu": {
                "bleu": 0.20846142134467513,
                "precisions": [
                    0.3881453154875717,
                    0.2662835249042146,
                    0.1727447216890595,
                    0.10576923076923077
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.760942760942761,
                "translation_length": 523,
                "reference_length": 297
            },
            "bert": {
                "precision": 0.7910522818565369,
                "recall": 0.794408917427063,
                "f1": 0.7927270531654358
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.21966527196652716,
            "rouge2": 0.10062893081761007,
            "rougeL": 0.13807531380753138,
            "rougeLsum": 0.13807531380753138,
            "bleu": {
                "bleu": 0.006231165234540737,
                "precisions": [
                    0.898989898989899,
                    0.6621621621621622,
                    0.4576271186440678,
                    0.3197278911564626
                ],
                "brevity_penalty": 0.01147007891189161,
                "length_ratio": 0.1828817733990148,
                "translation_length": 297,
                "reference_length": 1624
            },
            "bert": {
                "precision": 0.7987933158874512,
                "recall": 0.7569900155067444,
                "f1": 0.7773301005363464
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.3244239631336406,
            "rouge2": 0.097876269621422,
            "rougeL": 0.18801843317972353,
            "rougeLsum": 0.18801843317972353,
            "bleu": {
                "bleu": 0.04277898496462511,
                "precisions": [
                    0.7820267686424475,
                    0.4789272030651341,
                    0.2706333973128599,
                    0.15
                ],
                "brevity_penalty": 0.12182587304395984,
                "length_ratio": 0.32204433497536944,
                "translation_length": 523,
                "reference_length": 1624
            },
            "bert": {
                "precision": 0.7830764055252075,
                "recall": 0.7445991337299347,
                "f1": 0.7633358538150787
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.2663185378590079,
            "rouge2": 0.08398950131233596,
            "rougeL": 0.20365535248041775,
            "rougeLsum": 0.20365535248041775,
            "bleu": {
                "bleu": 0.17189030827326834,
                "precisions": [
                    0.6835016835016835,
                    0.46959459459459457,
                    0.3050847457627119,
                    0.1870748299319728
                ],
                "brevity_penalty": 0.4672257371335257,
                "length_ratio": 0.5678776290630975,
                "translation_length": 297,
                "reference_length": 523
            },
            "bert": {
                "precision": 0.794408917427063,
                "recall": 0.7910522818565369,
                "f1": 0.7927270531654358
            }
        },
        "gpt-4o": {
            "rouge1": 0.3244239631336406,
            "rouge2": 0.097876269621422,
            "rougeL": 0.18801843317972353,
            "rougeLsum": 0.18801843317972353,
            "bleu": {
                "bleu": 0.112865096085174,
                "precisions": [
                    0.2518472906403941,
                    0.15403573629081946,
                    0.08692971639950678,
                    0.048118445404071564
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 3.1051625239005736,
                "translation_length": 1624,
                "reference_length": 523
            },
            "bert": {
                "precision": 0.7445991337299347,
                "recall": 0.7830764055252075,
                "f1": 0.7633358538150787
            }
        }
    }
}