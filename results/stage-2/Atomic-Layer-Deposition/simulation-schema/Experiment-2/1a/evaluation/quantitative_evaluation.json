{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.34519956850053934,
            "rouge2": 0.18378378378378377,
            "rougeL": 0.21574973031283712,
            "rougeLsum": 0.21574973031283712,
            "bleu": {
                "bleu": 0.14647575531275403,
                "precisions": [
                    0.2447289156626506,
                    0.17935192162773173,
                    0.12518853695324283,
                    0.08377358490566038
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 3.405128205128205,
                "translation_length": 1328,
                "reference_length": 390
            },
            "bert": {
                "precision": 0.6757108569145203,
                "recall": 0.706104576587677,
                "f1": 0.6905728876590729
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.2832764505119454,
            "rouge2": 0.08219178082191782,
            "rougeL": 0.20477815699658705,
            "rougeLsum": 0.20477815699658705,
            "bleu": {
                "bleu": 0.14990570534530295,
                "precisions": [
                    0.2890625,
                    0.18904823989569752,
                    0.12402088772845953,
                    0.07450980392156863
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.9692307692307693,
                "translation_length": 768,
                "reference_length": 390
            },
            "bert": {
                "precision": 0.6528509259223938,
                "recall": 0.6722320914268494,
                "f1": 0.6623674035072327
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.34519956850053934,
            "rouge2": 0.18378378378378377,
            "rougeL": 0.21574973031283712,
            "rougeLsum": 0.21574973031283712,
            "bleu": {
                "bleu": 0.04513876927617952,
                "precisions": [
                    0.8333333333333334,
                    0.6118251928020566,
                    0.42783505154639173,
                    0.2868217054263566
                ],
                "brevity_penalty": 0.09025392385214229,
                "length_ratio": 0.2936746987951807,
                "translation_length": 390,
                "reference_length": 1328
            },
            "bert": {
                "precision": 0.706104576587677,
                "recall": 0.6757108569145203,
                "f1": 0.6905728876590729
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.46438482886216464,
            "rouge2": 0.1705282669138091,
            "rougeL": 0.29787234042553185,
            "rougeLsum": 0.29787234042553185,
            "bleu": {
                "bleu": 0.18451264841007703,
                "precisions": [
                    0.7734375,
                    0.49282920469361147,
                    0.2924281984334204,
                    0.19215686274509805
                ],
                "brevity_penalty": 0.4823107482912781,
                "length_ratio": 0.5783132530120482,
                "translation_length": 768,
                "reference_length": 1328
            },
            "bert": {
                "precision": 0.8085153698921204,
                "recall": 0.7608669400215149,
                "f1": 0.7833792368570963
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.2832764505119454,
            "rouge2": 0.08219178082191782,
            "rougeL": 0.20477815699658705,
            "rougeLsum": 0.20477815699658705,
            "bleu": {
                "bleu": 0.11220418611938561,
                "precisions": [
                    0.5692307692307692,
                    0.37275064267352187,
                    0.24484536082474226,
                    0.14728682170542637
                ],
                "brevity_penalty": 0.3793747526239096,
                "length_ratio": 0.5078125,
                "translation_length": 390,
                "reference_length": 768
            },
            "bert": {
                "precision": 0.6722321212291718,
                "recall": 0.6528509259223938,
                "f1": 0.662367433309555
            }
        },
        "gpt-4o": {
            "rouge1": 0.46438482886216464,
            "rouge2": 0.1705282669138091,
            "rougeL": 0.29787234042553185,
            "rougeLsum": 0.29787234042553185,
            "bleu": {
                "bleu": 0.22105675953166087,
                "precisions": [
                    0.44728915662650603,
                    0.2848530519969857,
                    0.1689291101055807,
                    0.1109433962264151
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.7291666666666667,
                "translation_length": 1328,
                "reference_length": 768
            },
            "bert": {
                "precision": 0.7608669400215149,
                "recall": 0.8085153500239054,
                "f1": 0.7833792169888815
            }
        }
    }
}