{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.6357142857142857,
            "rouge2": 0.32458233890214794,
            "rougeL": 0.30714285714285716,
            "rougeLsum": 0.30714285714285716,
            "bleu": {
                "bleu": 0.4501426684337471,
                "precisions": [
                    0.7848605577689243,
                    0.5452127659574468,
                    0.4207723035952064,
                    0.31866666666666665
                ],
                "brevity_penalty": 0.9197390056978114,
                "length_ratio": 0.9227941176470589,
                "translation_length": 753,
                "reference_length": 816
            },
            "bert": {
                "precision": 0.8208471735318502,
                "recall": 0.7985158960024515,
                "f1": 0.8094381292661031
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5766590389016018,
            "rouge2": 0.29128440366972475,
            "rougeL": 0.3363844393592677,
            "rougeLsum": 0.3363844393592677,
            "bleu": {
                "bleu": 0.2803929324562109,
                "precisions": [
                    0.6560332871012483,
                    0.3958333333333333,
                    0.2517385257301808,
                    0.16016713091922005
                ],
                "brevity_penalty": 0.8765500777861022,
                "length_ratio": 0.883578431372549,
                "translation_length": 721,
                "reference_length": 816
            },
            "bert": {
                "precision": 0.7877567013104757,
                "recall": 0.7525476813316345,
                "f1": 0.7695857087771097
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.6357142857142857,
            "rouge2": 0.32458233890214794,
            "rougeL": 0.30714285714285716,
            "rougeLsum": 0.30714285714285716,
            "bleu": {
                "bleu": 0.4515682520208723,
                "precisions": [
                    0.7242647058823529,
                    0.5030674846625767,
                    0.3882063882063882,
                    0.2939729397293973
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.0836653386454183,
                "translation_length": 816,
                "reference_length": 753
            },
            "bert": {
                "precision": 0.7985158960024515,
                "recall": 0.8208471735318502,
                "f1": 0.8094381292661031
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.6060606060606061,
            "rouge2": 0.31139240506329113,
            "rougeL": 0.35353535353535354,
            "rougeLsum": 0.35353535353535354,
            "bleu": {
                "bleu": 0.33168608278796924,
                "precisions": [
                    0.6768377253814147,
                    0.4375,
                    0.27816411682892905,
                    0.17548746518105848
                ],
                "brevity_penalty": 0.9565877040111047,
                "length_ratio": 0.9575033200531209,
                "translation_length": 721,
                "reference_length": 753
            },
            "bert": {
                "precision": 0.8159439365069071,
                "recall": 0.8066808382670084,
                "f1": 0.8112708727518717
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.5766590389016018,
            "rouge2": 0.29128440366972475,
            "rougeL": 0.3363844393592677,
            "rougeLsum": 0.3363844393592677,
            "bleu": {
                "bleu": 0.28257251986817317,
                "precisions": [
                    0.5796568627450981,
                    0.3496932515337423,
                    0.22235872235872237,
                    0.14145141451414514
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.131761442441054,
                "translation_length": 816,
                "reference_length": 721
            },
            "bert": {
                "precision": 0.7525476813316345,
                "recall": 0.7877567013104757,
                "f1": 0.7695857087771097
            }
        },
        "gpt-4o": {
            "rouge1": 0.6060606060606061,
            "rouge2": 0.31139240506329113,
            "rougeL": 0.35353535353535354,
            "rougeLsum": 0.35353535353535354,
            "bleu": {
                "bleu": 0.3319741173258805,
                "precisions": [
                    0.648074369189907,
                    0.41888297872340424,
                    0.2663115845539281,
                    0.168
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.044382801664355,
                "translation_length": 753,
                "reference_length": 721
            },
            "bert": {
                "precision": 0.8066808382670084,
                "recall": 0.8159439563751221,
                "f1": 0.8112708926200867
            }
        }
    }
}
