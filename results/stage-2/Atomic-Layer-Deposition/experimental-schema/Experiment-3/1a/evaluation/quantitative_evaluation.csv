Reference,Comparison,rouge1,rouge2,rougeL,rougeLsum,bleu_bleu,bleu_precisions,bleu_brevity_penalty,bleu_length_ratio,bleu_translation_length,bleu_reference_length,bert_precision,bert_recall,bert_f1
gpt-4-turbo,gpt-4o,0.329268293,0.146639511,0.18699187,0.18699187,0.126183775,"[0.212707182320442, 0.14512785072563925, 0.1078838174273859, 0.07612456747404844]",1,3.703324808,1448,391,0.706252933,0.71901685,0.710755229
,meta-llama-3.1-8b-instruct,0.315789474,0.136422136,0.202824134,0.202824134,0.113104224,"[0.22796934865900384, 0.13518696069031638, 0.09213051823416507, 0.05763688760806916]",1,2.670076726,1044,391,0.703627139,0.707749009,0.703733116
gpt-4o,gpt-4-turbo,0.329268293,0.146639511,0.18699187,0.18699187,0.031388973,"[0.7877237851662404, 0.5384615384615384, 0.40102827763496146, 0.28350515463917525]",0.066982438,0.270027624,391,1448,0.71901685,0.706252903,0.710755199
,meta-llama-3.1-8b-instruct,0.511128166,0.21829362,0.294704528,0.294704528,0.211737513,"[0.6657088122605364, 0.4084372003835091, 0.2495201535508637, 0.13928914505283382]",0.679109308,0.720994475,1044,1448,0.77045624,0.752373144,0.761263922
meta-llama-3.1-8b-instruct,gpt-4-turbo,0.315789474,0.136422136,0.202824134,0.202824134,0.05698281,"[0.6086956521739131, 0.36153846153846153, 0.2467866323907455, 0.15463917525773196]",0.188232623,0.374521073,391,1044,0.707748979,0.703627169,0.703733116
,gpt-4o,0.511128166,0.21829362,0.294704528,0.294704528,0.224706497,"[0.47997237569060774, 0.29440221147201107, 0.1798063623789765, 0.10034602076124567]",1,1.38697318,1448,1044,0.752373144,0.77045624,0.761263922
