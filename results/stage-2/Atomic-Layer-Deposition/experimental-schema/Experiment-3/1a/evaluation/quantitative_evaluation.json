{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.3292682926829268,
            "rouge2": 0.14663951120162932,
            "rougeL": 0.18699186991869918,
            "rougeLsum": 0.18699186991869918,
            "bleu": {
                "bleu": 0.1261837748588741,
                "precisions": [
                    0.212707182320442,
                    0.14512785072563925,
                    0.1078838174273859,
                    0.07612456747404844
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 3.703324808184143,
                "translation_length": 1448,
                "reference_length": 391
            },
            "bert": {
                "precision": 0.706252932548523,
                "recall": 0.7190168499946594,
                "f1": 0.7107552289962769
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.3157894736842105,
            "rouge2": 0.13642213642213644,
            "rougeL": 0.20282413350449296,
            "rougeLsum": 0.20282413350449296,
            "bleu": {
                "bleu": 0.11310422399087718,
                "precisions": [
                    0.22796934865900384,
                    0.13518696069031638,
                    0.09213051823416507,
                    0.05763688760806916
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 2.670076726342711,
                "translation_length": 1044,
                "reference_length": 391
            },
            "bert": {
                "precision": 0.7036271393299103,
                "recall": 0.7077490091323853,
                "f1": 0.7037331163883209
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.3292682926829268,
            "rouge2": 0.14663951120162932,
            "rougeL": 0.18699186991869918,
            "rougeLsum": 0.18699186991869918,
            "bleu": {
                "bleu": 0.03138897281169267,
                "precisions": [
                    0.7877237851662404,
                    0.5384615384615384,
                    0.40102827763496146,
                    0.28350515463917525
                ],
                "brevity_penalty": 0.06698243834625282,
                "length_ratio": 0.27002762430939226,
                "translation_length": 391,
                "reference_length": 1448
            },
            "bert": {
                "precision": 0.7190168499946594,
                "recall": 0.7062529027462006,
                "f1": 0.7107551991939545
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5111281657712969,
            "rouge2": 0.21829362029208302,
            "rougeL": 0.29470452801227937,
            "rougeLsum": 0.29470452801227937,
            "bleu": {
                "bleu": 0.21173751306794453,
                "precisions": [
                    0.6657088122605364,
                    0.4084372003835091,
                    0.2495201535508637,
                    0.13928914505283382
                ],
                "brevity_penalty": 0.6791093083420052,
                "length_ratio": 0.7209944751381215,
                "translation_length": 1044,
                "reference_length": 1448
            },
            "bert": {
                "precision": 0.7704562395811081,
                "recall": 0.752373144030571,
                "f1": 0.7612639218568802
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.3157894736842105,
            "rouge2": 0.13642213642213644,
            "rougeL": 0.20282413350449296,
            "rougeLsum": 0.20282413350449296,
            "bleu": {
                "bleu": 0.05698280960587956,
                "precisions": [
                    0.6086956521739131,
                    0.36153846153846153,
                    0.2467866323907455,
                    0.15463917525773196
                ],
                "brevity_penalty": 0.18823262268395882,
                "length_ratio": 0.37452107279693486,
                "translation_length": 391,
                "reference_length": 1044
            },
            "bert": {
                "precision": 0.7077489793300629,
                "recall": 0.7036271691322327,
                "f1": 0.7037331163883209
            }
        },
        "gpt-4o": {
            "rouge1": 0.5111281657712969,
            "rouge2": 0.21829362029208302,
            "rougeL": 0.29470452801227937,
            "rougeLsum": 0.29470452801227937,
            "bleu": {
                "bleu": 0.22470649738382753,
                "precisions": [
                    0.47997237569060774,
                    0.29440221147201107,
                    0.1798063623789765,
                    0.10034602076124567
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.3869731800766283,
                "translation_length": 1448,
                "reference_length": 1044
            },
            "bert": {
                "precision": 0.752373144030571,
                "recall": 0.7704562395811081,
                "f1": 0.7612639218568802
            }
        }
    }
}