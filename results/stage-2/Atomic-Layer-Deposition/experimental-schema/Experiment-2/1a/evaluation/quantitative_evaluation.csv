Reference,Comparison,rouge1,rouge2,rougeL,rougeLsum,bleu_bleu,bleu_precisions,bleu_brevity_penalty,bleu_length_ratio,bleu_translation_length,bleu_reference_length,bert_precision,bert_recall,bert_f1
gpt-4-turbo,gpt-4o,0.510717614,0.267040149,0.309412861,0.309412861,0.27877846,"[0.43613707165109034, 0.32424006235385816, 0.24102964118564743, 0.17720530835284934]",1,1.798319328,1284,714,0.785975218,0.782758713,0.784328401
,meta-llama-3.1-8b-instruct,0.422897196,0.180327869,0.280373832,0.280373832,0.2467482,"[0.45257142857142857, 0.30892448512585813, 0.19931271477663232, 0.13302752293577982]",1,1.225490196,875,714,0.773835927,0.752118558,0.762821406
gpt-4o,gpt-4-turbo,0.510717614,0.267040149,0.309412861,0.309412861,0.225853285,"[0.7843137254901961, 0.5834502103786816, 0.4339887640449438, 0.31926863572433195]",0.450084774,0.556074766,714,1284,0.782758713,0.785975218,0.784328401
,meta-llama-3.1-8b-instruct,0.491479821,0.219227314,0.294170404,0.294170404,0.254389096,"[0.7371428571428571, 0.488558352402746, 0.3321878579610538, 0.22706422018348624]",0.626611485,0.681464174,875,1284,0.794131537,0.755799472,0.774478098
meta-llama-3.1-8b-instruct,gpt-4-turbo,0.422897196,0.180327869,0.280373832,0.280373832,0.241436577,"[0.5546218487394958, 0.37868162692847124, 0.2443820224719101, 0.1631504922644163]",0.798124885,0.816,714,875,0.752118558,0.773835927,0.762821406
,gpt-4o,0.491479821,0.219227314,0.294170404,0.294170404,0.27650659,"[0.5023364485981309, 0.3328137178487919, 0.22620904836193448, 0.15456674473067916]",1,1.467428571,1284,875,0.755799472,0.794131537,0.774478098
