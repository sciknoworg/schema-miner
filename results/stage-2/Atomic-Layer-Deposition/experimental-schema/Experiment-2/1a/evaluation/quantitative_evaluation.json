{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.51071761416589,
            "rouge2": 0.26704014939309056,
            "rougeL": 0.30941286113699906,
            "rougeLsum": 0.30941286113699906,
            "bleu": {
                "bleu": 0.2787784600826554,
                "precisions": [
                    0.43613707165109034,
                    0.32424006235385816,
                    0.24102964118564743,
                    0.17720530835284934
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.7983193277310925,
                "translation_length": 1284,
                "reference_length": 714
            },
            "bert": {
                "precision": 0.7859752178192139,
                "recall": 0.7827587127685547,
                "f1": 0.7843284010887146
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.42289719626168226,
            "rouge2": 0.18032786885245902,
            "rougeL": 0.28037383177570097,
            "rougeLsum": 0.28037383177570097,
            "bleu": {
                "bleu": 0.24674820005699502,
                "precisions": [
                    0.45257142857142857,
                    0.30892448512585813,
                    0.19931271477663232,
                    0.13302752293577982
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.2254901960784315,
                "translation_length": 875,
                "reference_length": 714
            },
            "bert": {
                "precision": 0.7738359272480011,
                "recall": 0.7521185576915741,
                "f1": 0.7628214061260223
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.51071761416589,
            "rouge2": 0.26704014939309056,
            "rougeL": 0.30941286113699906,
            "rougeLsum": 0.30941286113699906,
            "bleu": {
                "bleu": 0.2258532845040965,
                "precisions": [
                    0.7843137254901961,
                    0.5834502103786816,
                    0.4339887640449438,
                    0.31926863572433195
                ],
                "brevity_penalty": 0.45008477380311146,
                "length_ratio": 0.5560747663551402,
                "translation_length": 714,
                "reference_length": 1284
            },
            "bert": {
                "precision": 0.7827587127685547,
                "recall": 0.7859752178192139,
                "f1": 0.7843284010887146
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.4914798206278027,
            "rouge2": 0.21922731356693617,
            "rougeL": 0.294170403587444,
            "rougeLsum": 0.294170403587444,
            "bleu": {
                "bleu": 0.25438909577762187,
                "precisions": [
                    0.7371428571428571,
                    0.488558352402746,
                    0.3321878579610538,
                    0.22706422018348624
                ],
                "brevity_penalty": 0.626611485078883,
                "length_ratio": 0.6814641744548287,
                "translation_length": 875,
                "reference_length": 1284
            },
            "bert": {
                "precision": 0.7941315372784933,
                "recall": 0.7557994723320007,
                "f1": 0.7744780977567037
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.42289719626168226,
            "rouge2": 0.18032786885245902,
            "rougeL": 0.28037383177570097,
            "rougeLsum": 0.28037383177570097,
            "bleu": {
                "bleu": 0.24143657689647643,
                "precisions": [
                    0.5546218487394958,
                    0.37868162692847124,
                    0.2443820224719101,
                    0.1631504922644163
                ],
                "brevity_penalty": 0.7981248851633106,
                "length_ratio": 0.816,
                "translation_length": 714,
                "reference_length": 875
            },
            "bert": {
                "precision": 0.7521185576915741,
                "recall": 0.7738359272480011,
                "f1": 0.7628214061260223
            }
        },
        "gpt-4o": {
            "rouge1": 0.4914798206278027,
            "rouge2": 0.21922731356693617,
            "rougeL": 0.294170403587444,
            "rougeLsum": 0.294170403587444,
            "bleu": {
                "bleu": 0.2765065895944158,
                "precisions": [
                    0.5023364485981309,
                    0.3328137178487919,
                    0.22620904836193448,
                    0.15456674473067916
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.4674285714285715,
                "translation_length": 1284,
                "reference_length": 875
            },
            "bert": {
                "precision": 0.7557994723320007,
                "recall": 0.7941315372784933,
                "f1": 0.7744780977567037
            }
        }
    }
}