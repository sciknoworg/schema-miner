{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.46683046683046686,
            "rouge2": 0.20935960591133004,
            "rougeL": 0.28992628992628994,
            "rougeLsum": 0.28992628992628994,
            "bleu": {
                "bleu": 0.22278592409999542,
                "precisions": [
                    0.39026915113871635,
                    0.2632124352331606,
                    0.18775933609958506,
                    0.1277258566978193
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.8295454545454546,
                "translation_length": 966,
                "reference_length": 528
            },
            "bert": {
                "precision": 0.7812082767486572,
                "recall": 0.7611334025859833,
                "f1": 0.7705023288726807
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.4634146341463415,
            "rouge2": 0.20795107033639143,
            "rougeL": 0.29878048780487804,
            "rougeLsum": 0.29878048780487804,
            "bleu": {
                "bleu": 0.22715826129529337,
                "precisions": [
                    0.40789473684210525,
                    0.2708638360175695,
                    0.18035190615835778,
                    0.13362701908957417
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.2954545454545454,
                "translation_length": 684,
                "reference_length": 528
            },
            "bert": {
                "precision": 0.7899782061576843,
                "recall": 0.7298674881458282,
                "f1": 0.7583369314670563
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.46683046683046686,
            "rouge2": 0.20935960591133004,
            "rougeL": 0.28992628992628994,
            "rougeLsum": 0.28992628992628994,
            "bleu": {
                "bleu": 0.17804315376991495,
                "precisions": [
                    0.7140151515151515,
                    0.4819734345351044,
                    0.344106463878327,
                    0.2342857142857143
                ],
                "brevity_penalty": 0.4362475355958308,
                "length_ratio": 0.546583850931677,
                "translation_length": 528,
                "reference_length": 966
            },
            "bert": {
                "precision": 0.7611333727836609,
                "recall": 0.7812082767486572,
                "f1": 0.7705022990703583
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.510688836104513,
            "rouge2": 0.2285714285714286,
            "rougeL": 0.3040380047505938,
            "rougeLsum": 0.3040380047505938,
            "bleu": {
                "bleu": 0.28204436458313975,
                "precisions": [
                    0.7456140350877193,
                    0.5095168374816984,
                    0.3533724340175953,
                    0.24522760646108663
                ],
                "brevity_penalty": 0.6621383865568363,
                "length_ratio": 0.7080745341614907,
                "translation_length": 684,
                "reference_length": 966
            },
            "bert": {
                "precision": 0.8090372681617737,
                "recall": 0.7635108629862467,
                "f1": 0.785580555597941
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.4634146341463415,
            "rouge2": 0.20795107033639143,
            "rougeL": 0.29878048780487804,
            "rougeLsum": 0.29878048780487804,
            "bleu": {
                "bleu": 0.21913862574523094,
                "precisions": [
                    0.5284090909090909,
                    0.3510436432637571,
                    0.2338403041825095,
                    0.17333333333333334
                ],
                "brevity_penalty": 0.7441932409198289,
                "length_ratio": 0.7719298245614035,
                "translation_length": 528,
                "reference_length": 684
            },
            "bert": {
                "precision": 0.7298674881458282,
                "recall": 0.7899782061576843,
                "f1": 0.7583369314670563
            }
        },
        "gpt-4o": {
            "rouge1": 0.510688836104513,
            "rouge2": 0.2285714285714286,
            "rougeL": 0.3040380047505938,
            "rougeLsum": 0.3040380047505938,
            "bleu": {
                "bleu": 0.3014177289145419,
                "precisions": [
                    0.5279503105590062,
                    0.3606217616580311,
                    0.25,
                    0.17341640706126688
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.412280701754386,
                "translation_length": 966,
                "reference_length": 684
            },
            "bert": {
                "precision": 0.7635108629862467,
                "recall": 0.8090372284253439,
                "f1": 0.7855805357297262
            }
        }
    }
}