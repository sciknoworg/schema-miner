{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.5925250683682771,
            "rouge2": 0.30136986301369867,
            "rougeL": 0.317228805834093,
            "rougeLsum": 0.317228805834093,
            "bleu": {
                "bleu": 0.3581110709912598,
                "precisions": [
                    0.5651085141903172,
                    0.4227234753550543,
                    0.31521739130434784,
                    0.21841004184100418
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.4144037780401417,
                "translation_length": 1198,
                "reference_length": 847
            },
            "bert": {
                "precision": 0.7786035140355428,
                "recall": 0.7839601834615072,
                "f1": 0.7810930609703064
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.42588726513569936,
            "rouge2": 0.18619246861924685,
            "rougeL": 0.2755741127348643,
            "rougeLsum": 0.2755741127348643,
            "bleu": {
                "bleu": 0.25698301622300224,
                "precisions": [
                    0.473953013278856,
                    0.32515337423312884,
                    0.21084953940634596,
                    0.13422131147540983
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.155844155844156,
                "translation_length": 979,
                "reference_length": 847
            },
            "bert": {
                "precision": 0.7522497177124023,
                "recall": 0.7437779506047567,
                "f1": 0.7478713194529215
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.5925250683682771,
            "rouge2": 0.30136986301369867,
            "rougeL": 0.317228805834093,
            "rougeLsum": 0.317228805834093,
            "bleu": {
                "bleu": 0.3348449507598109,
                "precisions": [
                    0.7992916174734357,
                    0.5981087470449172,
                    0.4461538461538462,
                    0.30924170616113744
                ],
                "brevity_penalty": 0.6607341074737356,
                "length_ratio": 0.7070116861435726,
                "translation_length": 847,
                "reference_length": 1198
            },
            "bert": {
                "precision": 0.7839601834615072,
                "recall": 0.7786034941673279,
                "f1": 0.7810930609703064
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.471441523118767,
            "rouge2": 0.1834695731153497,
            "rougeL": 0.27923844061650044,
            "rougeLsum": 0.27923844061650044,
            "bleu": {
                "bleu": 0.30071968553662626,
                "precisions": [
                    0.6843718079673136,
                    0.46421267893660534,
                    0.31525076765609006,
                    0.19979508196721313
                ],
                "brevity_penalty": 0.7995568433079694,
                "length_ratio": 0.8171953255425709,
                "translation_length": 979,
                "reference_length": 1198
            },
            "bert": {
                "precision": 0.7800927311182022,
                "recall": 0.7604269683361053,
                "f1": 0.7699973881244659
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.42588726513569936,
            "rouge2": 0.18619246861924685,
            "rougeL": 0.2755741127348643,
            "rougeLsum": 0.2755741127348643,
            "bleu": {
                "bleu": 0.25422919071940914,
                "precisions": [
                    0.5478158205430933,
                    0.375886524822695,
                    0.24378698224852072,
                    0.1552132701421801
                ],
                "brevity_penalty": 0.8556925346610108,
                "length_ratio": 0.8651685393258427,
                "translation_length": 847,
                "reference_length": 979
            },
            "bert": {
                "precision": 0.7437779506047567,
                "recall": 0.7522497177124023,
                "f1": 0.7478713194529215
            }
        },
        "gpt-4o": {
            "rouge1": 0.471441523118767,
            "rouge2": 0.1834695731153497,
            "rougeL": 0.27923844061650044,
            "rougeLsum": 0.27923844061650044,
            "bleu": {
                "bleu": 0.3072673978323432,
                "precisions": [
                    0.5592654424040067,
                    0.379281537176274,
                    0.25752508361204013,
                    0.16317991631799164
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.2236976506639428,
                "translation_length": 1198,
                "reference_length": 979
            },
            "bert": {
                "precision": 0.7604269236326218,
                "recall": 0.7800927460193634,
                "f1": 0.7699973732233047
            }
        }
    }
}