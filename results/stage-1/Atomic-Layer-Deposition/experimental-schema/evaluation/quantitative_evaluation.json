{
    "gpt-4-turbo": {
        "gpt-4o": {
            "rouge1": 0.5834586466165415,
            "rouge2": 0.301659125188537,
            "rougeL": 0.34285714285714286,
            "rougeLsum": 0.34285714285714286,
            "bleu": {
                "bleu": 0.39169509689146326,
                "precisions": [
                    0.8097826086956522,
                    0.5626134301270418,
                    0.4290909090909091,
                    0.3296903460837887
                ],
                "brevity_penalty": 0.7773911892790603,
                "length_ratio": 0.7988422575976846,
                "translation_length": 552,
                "reference_length": 691
            },
            "bert": {
                "precision": 0.83358034491539,
                "recall": 0.7875316441059113,
                "f1": 0.8098630607128143
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.5302445302445302,
            "rouge2": 0.26064516129032256,
            "rougeL": 0.41184041184041187,
            "rougeLsum": 0.41184041184041187,
            "bleu": {
                "bleu": 0.3481785943625539,
                "precisions": [
                    0.515,
                    0.3867334167709637,
                    0.30952380952380953,
                    0.2383939774153074
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.1577424023154848,
                "translation_length": 800,
                "reference_length": 691
            },
            "bert": {
                "precision": 0.802770584821701,
                "recall": 0.7520859837532043,
                "f1": 0.7765786647796631
            }
        }
    },
    "gpt-4o": {
        "gpt-4-turbo": {
            "rouge1": 0.5834586466165415,
            "rouge2": 0.301659125188537,
            "rougeL": 0.34285714285714286,
            "rougeLsum": 0.34285714285714286,
            "bleu": {
                "bleu": 0.40228260071860156,
                "precisions": [
                    0.6468885672937771,
                    0.4492753623188406,
                    0.34252539912917274,
                    0.26308139534883723
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.2518115942028984,
                "translation_length": 691,
                "reference_length": 552
            },
            "bert": {
                "precision": 0.7875316441059113,
                "recall": 0.83358034491539,
                "f1": 0.8098630607128143
            }
        },
        "meta-llama-3.1-8b-instruct": {
            "rouge1": 0.44984802431610943,
            "rouge2": 0.21036585365853658,
            "rougeL": 0.3100303951367781,
            "rougeLsum": 0.3100303951367781,
            "bleu": {
                "bleu": 0.2862831270005329,
                "precisions": [
                    0.46875,
                    0.3454317897371715,
                    0.24310776942355888,
                    0.17063989962358847
                ],
                "brevity_penalty": 1.0,
                "length_ratio": 1.4492753623188406,
                "translation_length": 800,
                "reference_length": 552
            },
            "bert": {
                "precision": 0.8102751672267914,
                "recall": 0.7988165318965912,
                "f1": 0.8044992685317993
            }
        }
    },
    "meta-llama-3.1-8b-instruct": {
        "gpt-4-turbo": {
            "rouge1": 0.5302445302445302,
            "rouge2": 0.26064516129032256,
            "rougeL": 0.41184041184041187,
            "rougeLsum": 0.41184041184041187,
            "bleu": {
                "bleu": 0.3443786410761196,
                "precisions": [
                    0.5962373371924746,
                    0.44782608695652176,
                    0.3584905660377358,
                    0.2761627906976744
                ],
                "brevity_penalty": 0.8540697600269435,
                "length_ratio": 0.86375,
                "translation_length": 691,
                "reference_length": 800
            },
            "bert": {
                "precision": 0.7520859837532043,
                "recall": 0.802770584821701,
                "f1": 0.7765786647796631
            }
        },
        "gpt-4o": {
            "rouge1": 0.44984802431610943,
            "rouge2": 0.21036585365853658,
            "rougeL": 0.3100303951367781,
            "rougeLsum": 0.3100303951367781,
            "bleu": {
                "bleu": 0.26496957471366694,
                "precisions": [
                    0.6793478260869565,
                    0.5009074410163339,
                    0.3527272727272727,
                    0.24772313296903462
                ],
                "brevity_penalty": 0.6380903684566482,
                "length_ratio": 0.69,
                "translation_length": 552,
                "reference_length": 800
            },
            "bert": {
                "precision": 0.7988165318965912,
                "recall": 0.8102751672267914,
                "f1": 0.8044992685317993
            }
        }
    }
}